#!/usr/bin/env python3
"""
ä»»åŠ¡è°ƒåº¦å¼•æ“
å®ç°ç¬¦åˆMCPæ ‡å‡†çš„ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œå¼•æ“
"""

import asyncio
import json
import logging
import os
import time
import jmespath
import re
import urllib.parse
from typing import Dict, Any, List, Optional, Tuple, Callable
import ast

from .llm_clients.openai_client import OpenAIClient
from .tool_executor import ToolExecutor


class TaskEngine:
    """ä»»åŠ¡è°ƒåº¦å¼•æ“"""
    
    def __init__(self, tool_registry, max_depth=5, status_callback=None):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.tool_registry = tool_registry
        self.max_depth = max_depth
        self.status_callback = status_callback  # WebSocketçŠ¶æ€å›è°ƒ
        
        # ä»ç¯å¢ƒå˜é‡è·å–OpenAIé…ç½®
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_API_BASE")
        model = os.getenv("OPENAI_MODEL", "gpt-4-turbo")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆå¦‚æœæœ‰API keyçš„è¯ï¼‰
        if api_key:
            try:
                self.llm = OpenAIClient(
                    api_key=api_key,
                    model=model,
                    base_url=base_url
                )
                self.logger.info("LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.llm = None
        else:
            self.logger.info("æœªè®¾ç½®OPENAI_API_KEYï¼ŒLLMåŠŸèƒ½å°†å—é™")
            self.llm = None
        
        # åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨
        self.tool_executor = ToolExecutor(tool_registry)
    
    def set_status_callback(self, callback: Callable):
        """è®¾ç½®çŠ¶æ€å›è°ƒå‡½æ•°"""
        self.status_callback = callback
        self.logger.info("çŠ¶æ€å›è°ƒå·²è®¾ç½®")
    
    async def _send_status_update(self, message_type: str, **kwargs):
        """å‘é€çŠ¶æ€æ›´æ–°"""
        if self.status_callback:
            try:
                message = {
                    "type": message_type,
                    "timestamp": time.time(),
                    **kwargs
                }
                self.logger.info(f"ğŸ“¤ å‘é€çŠ¶æ€æ›´æ–°: {message_type} - {kwargs.get('message', '')}")
                await self.status_callback(message)
            except Exception as e:
                self.logger.warning(f"çŠ¶æ€æ›´æ–°å‘é€å¤±è´¥: {e}")
        else:
            self.logger.warning(f"âš ï¸ çŠ¶æ€å›è°ƒæœªè®¾ç½®ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°: {message_type}")
    
    async def execute(self, query: str, context: dict) -> dict:
        """
        æ‰§è¡Œä»»åŠ¡ - æ”¯æŒæ™ºèƒ½æ¨¡å¼åˆ¤æ–­
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        start_time = time.time()
        
        try:
            # 1. æ™ºèƒ½åˆ¤æ–­ï¼šæ˜¯å¦éœ€è¦å·¥å…·æ‰§è¡Œ
            task_mode = await self._detect_task_mode(query)
            self.logger.info(f"æ¨¡å¼æ£€æµ‹ç»“æœ: {'ä»»åŠ¡æ¨¡å¼' if task_mode else 'é—²èŠæ¨¡å¼'} - æŸ¥è¯¢: {query[:50]}...")
            
            # å‘é€æ¨¡å¼æ£€æµ‹ç»“æœ
            await self._send_status_update("mode_detection", 
                mode="task" if task_mode else "chat",
                message=f"æ£€æµ‹åˆ°{'ä»»åŠ¡æ‰§è¡Œ' if task_mode else 'é—²èŠå¯¹è¯'}æ¨¡å¼"
            )
            
            if not task_mode:
                # é—²èŠæ¨¡å¼ï¼šç›´æ¥ç”¨LLMå›ç­”ï¼Œä¸è§¦å‘å·¥å…·æ‰§è¡Œ
                result = await self._handle_chat_mode(query, start_time)
                await self._send_status_update("chat_response", 
                    message=result.get("final_output", ""),
                    execution_time=result.get("execution_time", 0)
                )
                return result
            
            # 2. ä»»åŠ¡æ¨¡å¼ï¼šè¿›è¡Œå·¥å…·è§„åˆ’ä¸æ‰§è¡Œ
            # å°†åŸå§‹æŸ¥è¯¢æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä¾›åç»­å¤„ç†ä½¿ç”¨
            enhanced_context = {**context, "original_query": query}
            
            # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            self.logger.info(f"å¼€å§‹ç”Ÿæˆæ‰§è¡Œè®¡åˆ’: {query[:50]}...")
            await self._send_status_update("task_planning", message="æ­£åœ¨ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")
            
            execution_plan = await self._generate_plan(query, enhanced_context)
            
            if not execution_plan:
                error_result = {
                    "success": False,
                    "error": "Failed to generate execution plan",
                    "final_output": "æ— æ³•ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œè¯·å°è¯•é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚",
                    "execution_time": time.time() - start_time
                }
                await self._send_status_update("error", message="æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå¤±è´¥")
                return error_result
            
            # å‘é€ä»»åŠ¡å¼€å§‹å’Œè®¡åˆ’ä¿¡æ¯
            await self._send_status_update("task_start", 
                message=f"å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼Œå…±{len(execution_plan)}ä¸ªæ­¥éª¤",
                plan={"steps": execution_plan, "query": query}
            )
            
            # æ‰§è¡Œè®¡åˆ’
            self.logger.info(f"å¼€å§‹æ‰§è¡Œè®¡åˆ’ï¼Œå…±{len(execution_plan)}ä¸ªæ­¥éª¤")
            result = await self._execute_plan(execution_plan, enhanced_context)
            
            # æ·»åŠ æ‰§è¡Œæ—¶é—´å’Œæ¨¡å¼æ ‡è¯†
            result['execution_time'] = time.time() - start_time
            result['mode'] = 'task'
            
            # å‘é€ä»»åŠ¡å®Œæˆæ¶ˆæ¯
            await self._send_status_update("task_complete", 
                message=result.get("final_output", "ä»»åŠ¡æ‰§è¡Œå®Œæˆ"),
                execution_time=result['execution_time']
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            error_result = {
                "success": False,
                "error": str(e),
                "error_code": "TASK_EXECUTION_ERROR",
                "final_output": f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}",
                "execution_time": time.time() - start_time,
                "mode": "error"
            }
            await self._send_status_update("error", message=f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return error_result
    
    async def _detect_task_mode(self, query: str) -> bool:
        """
        æ™ºèƒ½æ£€æµ‹æŸ¥è¯¢æ˜¯å¦éœ€è¦å·¥å…·æ‰§è¡Œ
        
        ä½¿ç”¨é€šç”¨çš„è¯­ä¹‰ç†è§£è€Œä¸æ˜¯ç©·ä¸¾æ¨¡å¼åŒ¹é…
        
        Returns:
            True: éœ€è¦å·¥å…·æ‰§è¡Œçš„ä»»åŠ¡æ¨¡å¼
            False: æ™®é€šé—²èŠæ¨¡å¼
        """
        # 1. å¿«é€Ÿé•¿åº¦è¿‡æ»¤
        if len(query.strip()) < 2:
            return False
        
        # 2. ä½¿ç”¨LLMè¿›è¡Œé€šç”¨è¯­ä¹‰åˆ¤æ–­ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        if self.llm and hasattr(self.llm, 'generate'):
            try:
                return await self._llm_detect_task_mode_universal(query)
            except Exception as e:
                self.logger.warning(f"LLMé€šç”¨æ¨¡å¼æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–åˆ¤æ–­: {e}")
        
        # 3. ç®€åŒ–çš„å›é€€è§„åˆ™ï¼ˆä»…ä¿ç•™æœ€åŸºæœ¬çš„ï¼‰
        return self._basic_fallback_detection(query)
    
    async def _llm_detect_task_mode_universal(self, query: str) -> bool:
        """ä½¿ç”¨LLMè¿›è¡Œé€šç”¨è¯­ä¹‰æ£€æµ‹ï¼Œä¸ä¾èµ–ç¡¬ç¼–ç è§„åˆ™"""
        prompt = f"""åˆ¤æ–­ç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾ç±»å‹ã€‚

ç”¨æˆ·æŸ¥è¯¢: "{query}"

åˆ†ç±»æ ‡å‡†ï¼š

ã€é—²èŠå¯¹è¯ã€‘- çº¯ç¤¾äº¤äº¤æµï¼Œä¸éœ€è¦æŸ¥æ‰¾ä¿¡æ¯æˆ–ä½¿ç”¨å·¥å…·ï¼š
â€¢ é—®å€™å¯’æš„ï¼š"ä½ å¥½"ã€"åƒäº†å—"ã€"æœ€è¿‘æ€ä¹ˆæ ·"ã€"èº«ä½“å¥½å—"ã€"æ‚¨é‚£..."ã€"åƒäº†å—ï¼Ÿæ‚¨é‚£..."
â€¢ æ„Ÿè°¢å‘Šåˆ«ï¼š"è°¢è°¢"ã€"å†è§"ã€"è¾›è‹¦äº†"
â€¢ ç¡®è®¤å›åº”ï¼š"å¥½çš„"ã€"çŸ¥é“äº†"ã€"æ˜¯çš„"ã€"å—¯"ã€"å“¦"
â€¢ å…³æ€€é—²èŠï¼š"å·¥ä½œæ€ä¹ˆæ ·"ã€"ä»Šå¤©å¿ƒæƒ…å¦‚ä½•"ã€"ä¼‘æ¯ä¸€ä¸‹å§"ã€"å¿™ä¸å¿™"ã€"ç´¯ä¸ç´¯"
â€¢ ä¸€èˆ¬æ€§è¯¢é—®ï¼š"ä½ æ˜¯æœºå™¨äººå—"ã€"ä½ ä¼šä»€ä¹ˆ"ã€"ä½ èƒ½åšä»€ä¹ˆ"ã€"ç¡å¾—å¥½å—"
â€¢ ä¸å®Œæ•´çš„é—®å€™ï¼šå¥å­ä¸å®Œæ•´æˆ–è¢«æˆªæ–­çš„ç¤¾äº¤æ€§è¡¨è¾¾
â€¢ ç®€å•å›å¤ï¼šå•çº¯çš„ç¡®è®¤ã€æ„Ÿå¹æˆ–ç®€çŸ­ååº”

ã€ä»»åŠ¡è¯·æ±‚ã€‘- éœ€è¦è·å–ä¿¡æ¯ã€æ‰§è¡Œæ“ä½œæˆ–ä½¿ç”¨å·¥å…·ï¼š
â€¢ çŸ¥è¯†è¯¢é—®ï¼š"è°æ˜¯XX"ã€"ä»€ä¹ˆæ˜¯XX"ã€"å¦‚ä½•åšXX"ã€"XXæ˜¯ä»€ä¹ˆæ„æ€"
â€¢ æœç´¢è¯·æ±‚ï¼š"æœç´¢XX"ã€"æŸ¥æ‰¾XX"ã€"å¸®æˆ‘æ‰¾XX"ã€"XXçš„ä¿¡æ¯"
â€¢ å·¥å…·ä½¿ç”¨ï¼š"ç¿»è¯‘XX"ã€"åˆ†æXX"ã€"ç”ŸæˆXXæŠ¥å‘Š"ã€"å¤„ç†XX"
â€¢ ä¿¡æ¯è·å–ï¼šåŒ…å«æ˜ç¡®çš„ä¿¡æ¯éœ€æ±‚æˆ–ç–‘é—®è¯ï¼ˆä»€ä¹ˆã€è°ã€å“ªé‡Œã€å¦‚ä½•ç­‰ï¼‰

é‡è¦æç¤ºï¼š
- å¦‚æœæŸ¥è¯¢æ˜¾ç„¶æ˜¯ç¤¾äº¤æ€§è´¨çš„å¯¹è¯ï¼ˆé—®å€™ã€å…³æ€€ã€æ„Ÿè°¢ç­‰ï¼‰ï¼Œå³ä½¿æœ‰ç–‘é—®è¯ä¹Ÿåº”å½’ç±»ä¸ºã€é—²èŠå¯¹è¯ã€‘
- åªæœ‰æ˜ç¡®éœ€è¦æŸ¥æ‰¾ä¿¡æ¯ã€æ‰§è¡Œä»»åŠ¡æˆ–ä½¿ç”¨å·¥å…·çš„æŸ¥è¯¢æ‰æ˜¯ã€ä»»åŠ¡è¯·æ±‚ã€‘
- ä¸å®Œæ•´æˆ–æ¨¡ç³Šçš„è¡¨è¾¾ï¼Œå¦‚æœæ˜æ˜¾æ˜¯ç¤¾äº¤æ€§è´¨ï¼Œåº”å½’ç±»ä¸ºã€é—²èŠå¯¹è¯ã€‘

å›ç­”æ ¼å¼ï¼šåªå›ç­”"é—²èŠå¯¹è¯"æˆ–"ä»»åŠ¡è¯·æ±‚"ã€‚"""
        
        try:
            response = await self.llm.generate(prompt, max_tokens=20, temperature=0.0)
            result = response.strip()
            self.logger.debug(f"LLMæ£€æµ‹ç»“æœ: '{query}' -> '{result}'")
            return "ä»»åŠ¡è¯·æ±‚" in result
        except Exception as e:
            self.logger.warning(f"LLMä»»åŠ¡æ£€æµ‹å¤±è´¥: {e}")
            return True  # é»˜è®¤å½“ä½œä»»åŠ¡å¤„ç†
    
    def _basic_fallback_detection(self, query: str) -> bool:
        """åŸºäºè¯­ä¹‰ç†è§£çš„å›é€€åˆ¤æ–­ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        query = query.strip()
        
        # 1. é•¿åº¦åˆ†æï¼šå¾ˆçŸ­çš„æŸ¥è¯¢æ›´å¯èƒ½æ˜¯é—²èŠ
        if len(query) <= 3:
            return False
        
        # 2. å¥å¼åˆ†æ
        # ç–‘é—®å¥é€šå¸¸è¡¨ç¤ºéœ€è¦è·å–ä¿¡æ¯ï¼ˆä»»åŠ¡ï¼‰
        has_question_mark = 'ï¼Ÿ' in query or '?' in query
        
        # ç–‘é—®è¯æ£€æµ‹ï¼ˆæ˜ç¡®çš„ä¿¡æ¯éœ€æ±‚ï¼‰
        question_words = ['ä»€ä¹ˆ', 'è°', 'å“ªé‡Œ', 'å“ªä¸ª', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å¤šå°‘', 'å‡ ']
        has_question_word = any(word in query for word in question_words)
        
        # ä»»åŠ¡åŠ¨è¯ï¼ˆæ˜ç¡®çš„æ“ä½œè¯·æ±‚ï¼‰
        task_verbs = ['æœç´¢', 'æŸ¥æ‰¾', 'æŸ¥è¯¢', 'å¸®æˆ‘', 'è¯·', 'åˆ†æ', 'å¤„ç†', 'ç”Ÿæˆ', 'åˆ›å»º', 'ç¿»è¯‘', 'è®¡ç®—']
        has_task_verb = any(verb in query for verb in task_verbs)
        
        # 3. ç¤¾äº¤æ€§æŒ‡æ ‡
        # é—®å€™è¯
        greeting_words = ['ä½ å¥½', 'hi', 'hello', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½']
        has_greeting = any(word in query for word in greeting_words)
        
        # æ„Ÿè°¢è¯
        thanks_words = ['è°¢è°¢', 'thanks', 'æ„Ÿè°¢']
        has_thanks = any(word in query for word in thanks_words)
        
        # å…³æ€€è¯¢é—®ï¼ˆç¤¾äº¤æ€§è´¨ï¼‰
        care_patterns = ['æ€ä¹ˆæ ·', 'å¥½å—', 'å¦‚ä½•', 'è¿˜å¥½', 'å¿™ä¸å¿™', 'ç´¯ä¸ç´¯']
        has_care = any(pattern in query for pattern in care_patterns)
        
        # 4. è¯­å¢ƒåˆ†æ
        # å¦‚æœåŒ…å«"ä½ "ä¸”ä¸æ˜¯è¯¢é—®å…·ä½“ä¿¡æ¯ï¼Œæ›´å¯èƒ½æ˜¯ç¤¾äº¤å¯¹è¯
        has_you = 'ä½ ' in query or 'You' in query.lower()
        
        # AIèº«ä»½ç›¸å…³è¯¢é—®ï¼ˆç¤¾äº¤æ€§è´¨ï¼‰ - æ›´ç²¾ç¡®çš„æ¨¡å¼
        ai_identity_patterns = ['ä½ æ˜¯è°', 'ä½ æ˜¯ä»€ä¹ˆ', 'æœºå™¨äººå—', 'ä½ ä¼šä»€ä¹ˆ', 'ä½ èƒ½åšä»€ä¹ˆ']
        has_ai_identity_question = any(pattern in query for pattern in ai_identity_patterns)
        
        # æ—¥å¸¸ç”Ÿæ´»è¯¢é—®
        daily_patterns = ['åƒäº†', 'ç¡äº†', 'èµ·åºŠ', 'ä¸‹ç­', 'ä¸Šç­', 'å›å®¶']
        has_daily = any(pattern in query for pattern in daily_patterns)
        
        # 5. çŸ¥è¯†æ€§è¯¢é—®æ£€æµ‹ï¼ˆæ–°å¢ï¼‰
        # æ£€æµ‹æ˜¯å¦æ˜¯è¯¢é—®å…·ä½“äººç‰©ã€äº‹ç‰©ã€æ¦‚å¿µç­‰çš„çŸ¥è¯†æ€§é—®é¢˜
        knowledge_indicators = [
            # å†å²äººç‰©ã€ç°ä»£äººç‰©
            r'[\u4e00-\u9fff]{2,4}æ˜¯è°',  # ä¸­æ–‡åå­—+æ˜¯è°
            r'è°æ˜¯[\u4e00-\u9fff]{2,4}',  # è°æ˜¯+ä¸­æ–‡åå­—
            # æ¦‚å¿µè¯¢é—®
            r'ä»€ä¹ˆæ˜¯[\u4e00-\u9fff]+',    # ä»€ä¹ˆæ˜¯+æ¦‚å¿µ
            r'[\u4e00-\u9fff]+æ˜¯ä»€ä¹ˆ',    # æ¦‚å¿µ+æ˜¯ä»€ä¹ˆ
            # åœ°ç‚¹è¯¢é—®
            r'[\u4e00-\u9fff]+åœ¨å“ªé‡Œ',    # åœ°ç‚¹+åœ¨å“ªé‡Œ
            r'å“ªé‡Œæœ‰[\u4e00-\u9fff]+',    # å“ªé‡Œæœ‰+äº‹ç‰©
        ]
        import re
        has_knowledge_question = any(re.search(pattern, query) for pattern in knowledge_indicators)
        
        # 6. åˆ¤æ–­é€»è¾‘ï¼ˆä¼˜åŒ–åï¼‰
        # æ˜ç¡®çš„ç¤¾äº¤æŒ‡æ ‡ä¼˜å…ˆ
        if has_greeting or has_thanks or has_daily:
            return False
        
        # AIèº«ä»½è¯¢é—®åˆ¤æ–­ä¸ºé—²èŠ
        if has_ai_identity_question:
            return False
            
        # å…³æ€€æ€§è¯¢é—®ï¼šå¦‚æœæ˜¯å¯¹"ä½ "çš„å…³æ€€è¯¢é—®ï¼Œæ›´å¯èƒ½æ˜¯é—²èŠ
        if has_you and has_care:
            return False
            
        # çŸ¥è¯†æ€§è¯¢é—®ä¼˜å…ˆåˆ¤æ–­ä¸ºä»»åŠ¡ï¼ˆæ–°å¢é€»è¾‘ï¼‰
        if has_knowledge_question:
            return True
            
        # æ˜ç¡®çš„ä»»åŠ¡æŒ‡æ ‡
        if has_question_word or has_task_verb:
            return True
        
        # ç–‘é—®å¥ä½†æ²¡æœ‰æ˜ç¡®ç–‘é—®è¯çš„æƒ…å†µ
        if has_question_mark:
            # å¦‚æœæ˜¯ç®€çŸ­çš„ç–‘é—®ä¸”åŒ…å«å…³æ€€è¯ï¼Œå€¾å‘äºé—²èŠ
            if len(query) <= 10 and has_care:
                return False
            # å¦åˆ™å¯èƒ½æ˜¯ä»»åŠ¡
            return True
        
        # é»˜è®¤ï¼šæ ¹æ®é•¿åº¦åˆ¤æ–­
        # è¾ƒé•¿çš„è¯­å¥æ›´å¯èƒ½åŒ…å«å…·ä½“éœ€æ±‚ï¼ˆä»»åŠ¡ï¼‰
        return len(query) > 8
    
    async def _handle_chat_mode(self, query: str, start_time: float) -> dict:
        """å¤„ç†é—²èŠæ¨¡å¼ - æ”¯æŒæµå¼è¾“å‡º"""
        try:
            # å‘é€å¼€å§‹å¤„ç†çŠ¶æ€
            await self._send_status_update("chat_processing", message="æ­£åœ¨ç”Ÿæˆå›å¤...")
            
            final_output = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"  # é»˜è®¤å›å¤
            
            if self.llm and hasattr(self.llm, 'generate_streaming'):
                try:
                    # ä½¿ç”¨LLMæµå¼ç”Ÿæˆå‹å¥½å›ç­”
                    chat_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·è¯´: "{query}"

è¯·ç»™å‡ºè‡ªç„¶ã€å‹å¥½çš„å›åº”ã€‚è¦æ±‚ï¼š
1. ä¿æŒç®€æ´æ˜äº†ï¼Œä¸è¦è¿‡äºå†—é•¿
2. è¯­æ°”äº²åˆ‡è‡ªç„¶ï¼Œå¦‚åŒæœ‹å‹é—´çš„å¯¹è¯
3. å¦‚æœç”¨æˆ·æ˜¯é—®å€™ï¼Œè¦ç¤¼è²Œå›åº”
4. å¦‚æœç”¨æˆ·è¡¨è¾¾æ„Ÿè°¢ï¼Œè¦è°¦é€Šå›å¤
5. å¦‚æœç”¨æˆ·è¯¢é—®ä½ çš„èƒ½åŠ›ï¼Œå¯ä»¥ç®€å•ä»‹ç»ä½ èƒ½å¸®åŠ©æœç´¢ä¿¡æ¯ã€å¤„ç†æ–‡ä»¶ç­‰

ç›´æ¥å›å¤ï¼Œä¸è¦æ ¼å¼åŒ–æ ‡è®°ã€‚
"""
                    messages = [{"role": "user", "content": chat_prompt}]
                    
                    # æµå¼ç”Ÿæˆå›å¤
                    content_buffer = ""
                    async for chunk in self.llm.generate_streaming(messages, max_tokens=100, temperature=0.7):
                        if chunk.get('type') == 'content':
                            content = chunk.get('content', '')
                            content_buffer += content
                            
                            # å‘é€æµå¼å†…å®¹æ›´æ–°
                            await self._send_status_update("chat_streaming", 
                                message=f"ç”Ÿæˆä¸­: {content_buffer}",
                                partial_content=content,
                                accumulated_content=content_buffer
                            )
                    
                    if content_buffer.strip():
                        final_output = content_buffer.strip()
                        
                except Exception as e:
                    self.logger.warning(f"LLMæµå¼å›å¤å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™å›å¤: {e}")
                    final_output = self._generate_rule_based_chat_response(query)
            elif self.llm and hasattr(self.llm, 'generate'):
                try:
                    # å›é€€åˆ°æ™®é€šLLMç”Ÿæˆ
                    chat_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·è¯´: "{query}"

è¯·ç»™å‡ºè‡ªç„¶ã€å‹å¥½çš„å›åº”ã€‚è¦æ±‚ï¼š
1. ä¿æŒç®€æ´æ˜äº†ï¼Œä¸è¦è¿‡äºå†—é•¿
2. è¯­æ°”äº²åˆ‡è‡ªç„¶ï¼Œå¦‚åŒæœ‹å‹é—´çš„å¯¹è¯
3. å¦‚æœç”¨æˆ·æ˜¯é—®å€™ï¼Œè¦ç¤¼è²Œå›åº”
4. å¦‚æœç”¨æˆ·è¡¨è¾¾æ„Ÿè°¢ï¼Œè¦è°¦é€Šå›å¤
5. å¦‚æœç”¨æˆ·è¯¢é—®ä½ çš„èƒ½åŠ›ï¼Œå¯ä»¥ç®€å•ä»‹ç»ä½ èƒ½å¸®åŠ©æœç´¢ä¿¡æ¯ã€å¤„ç†æ–‡ä»¶ç­‰

ç›´æ¥å›å¤ï¼Œä¸è¦æ ¼å¼åŒ–æ ‡è®°ã€‚
"""
                    response = await self.llm.generate(chat_prompt, max_tokens=100, temperature=0.7)
                    if response and response.strip():
                        final_output = response.strip()
                except Exception as e:
                    self.logger.warning(f"LLMé—²èŠå›å¤å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™å›å¤: {e}")
                    final_output = self._generate_rule_based_chat_response(query)
            else:
                # LLMä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨è§„åˆ™å›å¤ï¼ˆä¸æ¨¡æ‹Ÿæµå¼ï¼‰
                final_output = self._generate_rule_based_chat_response(query)
            
            return {
                "success": True,
                "final_output": final_output,
                "execution_steps": [],
                "step_count": 0,
                "error_count": 0,
                "mode": "chat",
                "execution_time": time.time() - start_time
            }
            
        except Exception as e:
            self.logger.warning(f"é—²èŠæ¨¡å¼å¤„ç†å¤±è´¥: {e}")
            return {
                "success": True,
                "final_output": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                "execution_steps": [],
                "step_count": 0,
                "error_count": 0,
                "mode": "chat",
                "execution_time": time.time() - start_time
            }
    
    def _generate_rule_based_chat_response(self, query: str) -> str:
        """åŸºäºè§„åˆ™ç”ŸæˆèŠå¤©å›å¤ï¼ˆä¸ä¾èµ–LLMï¼‰"""
        query_lower = query.lower().strip()
        
        # é—®å€™å›å¤
        if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hi', 'hello', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½']):
            greetings = [
                'ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°æ‚¨ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ',
                'æ‚¨å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œéšæ—¶å‡†å¤‡ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',
                'æ‚¨å¥½ï¼æœ‰ä»€ä¹ˆéœ€è¦æˆ‘ååŠ©çš„å—ï¼Ÿ'
            ]
            return greetings[len(query) % len(greetings)]
        
        # æ„Ÿè°¢å›å¤
        if any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'æ„Ÿè°¢']):
            thanks_responses = [
                'ä¸å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ã€‚',
                'ä¸ç”¨è°¢ï¼è¿™æ˜¯æˆ‘åº”è¯¥åšçš„ã€‚',
                'æ‚¨å¤ªå®¢æ°”äº†ï¼æœ‰å…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ'
            ]
            return thanks_responses[len(query) % len(thanks_responses)]
        
        # å‘Šåˆ«å›å¤
        if any(goodbye in query_lower for goodbye in ['å†è§', 'bye', 'æ‹œæ‹œ', 'goodbye']):
            goodbye_responses = [
                'å†è§ï¼å¸Œæœ›ä¸‹æ¬¡è¿˜èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',
                'æ‹œæ‹œï¼æœ‰éœ€è¦éšæ—¶æ‰¾æˆ‘å“¦ã€‚',
                'å†è§ï¼ç¥æ‚¨ä¸€åˆ‡é¡ºåˆ©ï¼'
            ]
            return goodbye_responses[len(query) % len(goodbye_responses)]
        
        # çŠ¶æ€è¯¢é—®
        if any(status in query_lower for status in ['æ€ä¹ˆæ ·', 'è¿˜å¥½å—', 'å¿™ä¸å¿™']):
            status_responses = [
                'æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢å…³å¿ƒï¼ä½œä¸ºAIåŠ©æ‰‹ï¼Œæˆ‘éšæ—¶å‡†å¤‡ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚',
                'æˆ‘çŠ¶æ€å¾ˆå¥½ï¼éšæ—¶å‡†å¤‡ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ',
                'æˆ‘ä¸ä¼šæ„Ÿåˆ°å¿™ç¢Œï¼Œéšæ—¶éƒ½å¯ä»¥ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼'
            ]
            return status_responses[len(query) % len(status_responses)]
        
        # èƒ½åŠ›è¯¢é—®
        if any(capability in query_lower for capability in ['ä½ æ˜¯è°', 'ä½ ä¼šä»€ä¹ˆ', 'ä½ èƒ½åšä»€ä¹ˆ', 'æœºå™¨äºº']):
            capability_responses = [
                'æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨æœç´¢ä¿¡æ¯ã€å¤„ç†æ–‡ä»¶ã€å›ç­”é—®é¢˜ç­‰ã€‚æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ',
                'æˆ‘å¯ä»¥å¸®æ‚¨æœç´¢ç½‘ç»œä¿¡æ¯ã€å¤„ç†å„ç§æ–‡ä»¶ã€å›ç­”é—®é¢˜ã€è¿›è¡Œæ•°æ®åˆ†æç­‰ã€‚æœ‰ä»€ä¹ˆå…·ä½“éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ',
                'æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥ä¸ºæ‚¨æä¾›ä¿¡æ¯æœç´¢ã€æ–‡ä»¶å¤„ç†ã€é—®é¢˜è§£ç­”ç­‰æœåŠ¡ã€‚å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©å§ï¼'
            ]
            return capability_responses[len(query) % len(capability_responses)]
        
        # ç¡®è®¤å›å¤
        if any(confirm in query_lower for confirm in ['å¥½çš„', 'ok', 'æ˜¯çš„', 'å¯¹çš„', 'å—¯', 'è¡Œ']):
            return 'å¥½çš„ï¼æœ‰ä»€ä¹ˆå…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ'
        
        # å¦å®šå›å¤
        if any(negative in query_lower for negative in ['ä¸æ˜¯', 'ä¸å¯¹', 'ä¸è¡Œ', 'no']):
            return 'å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†ã€‚æœ‰ä»€ä¹ˆå…¶ä»–å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ'
        
        # é»˜è®¤å‹å¥½å›å¤
        default_responses = [
            'æˆ‘æ˜ç™½äº†ã€‚ä½œä¸ºAIåŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨æœç´¢ä¿¡æ¯ã€å¤„ç†æ–‡ä»¶ç­‰ã€‚æœ‰ä»€ä¹ˆå…·ä½“éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ',
            'å¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ï¼æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›å„ç§å¸®åŠ©ï¼Œæ¯”å¦‚æœç´¢ä¿¡æ¯ã€å›ç­”é—®é¢˜ç­‰ã€‚',
            'æ„Ÿè°¢æ‚¨çš„äº¤æµï¼æˆ‘éšæ—¶å‡†å¤‡ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼Œæœ‰ä»€ä¹ˆéœ€è¦çš„å°½ç®¡è¯´ã€‚'
        ]
        
        # æ ¹æ®æŸ¥è¯¢é•¿åº¦å’Œå†…å®¹é€‰æ‹©åˆé€‚çš„å›å¤
        if len(query) <= 5:
            return default_responses[0]
        elif len(query) <= 15:
            return default_responses[1]
        else:
            return default_responses[2]
    
    async def _generate_plan(self, query: str, context: dict) -> List[dict]:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        try:
            # å·¥å…·æ¦‚è§ˆï¼ˆä¾¿äºäººè¯»ï¼‰
            tool_list_text = self._format_tool_list()
            # ç»“æ„åŒ–å·¥å…·å®šä¹‰ï¼ˆç²¾ç¡® schema æ³¨å…¥ï¼‰
            tools_json_block = json.dumps(self._get_tools_definitions_for_prompt(), ensure_ascii=False, indent=2)
            # éæ•æ„Ÿç¯å¢ƒæç¤ºï¼ˆä¾›LLMå‚è€ƒï¼‰
            env_hints_block = json.dumps(self._collect_non_sensitive_env_hints(), ensure_ascii=False, indent=2)
            
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡è§„åˆ’åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æŸ¥è¯¢å’Œå¯ç”¨å·¥å…·ï¼Œç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ã€‚

[ç”¨æˆ·ä¸Šä¸‹æ–‡]
{json.dumps(context, ensure_ascii=False, indent=2)}

[å¯ç”¨å·¥å…·ï¼ˆæ¦‚è§ˆï¼‰]
{tool_list_text}

[å¯ç”¨å·¥å…·ï¼ˆJSONï¼ŒåŒ…å«ç²¾ç¡®çš„å…¥å‚ä¸è¾“å‡ºSchemaï¼‰]
{tools_json_block}

[å¯ç”¨é»˜è®¤ç¯å¢ƒæç¤ºï¼ˆéæ•æ„Ÿï¼‰]
{env_hints_block}

[ç”¨æˆ·æŸ¥è¯¢]
{query}

å·¥å…·é€‰æ‹©æŒ‡å¯¼åŸåˆ™ï¼š
1. enhanced_report_generatorï¼šä»…ç”¨äºéœ€è¦ç”Ÿæˆä¸“ä¸šæŠ¥å‘Šã€åˆ†ææŠ¥å‘Šã€ç ”ç©¶æŠ¥å‘Šçš„åœºæ™¯
   - é€‚ç”¨ï¼šæ˜ç¡®è¦æ±‚"ç”ŸæˆæŠ¥å‘Š"ã€"åˆ†ææ€»ç»“"ã€"è¯¦ç»†ç ”ç©¶"ç­‰
   - ä¸é€‚ç”¨ï¼šç®€å•ä¿¡æ¯æŸ¥è¯¢ã€äººç‰©è¯¢é—®ã€æ¦‚å¿µè§£é‡Šç­‰
2. æœç´¢ç±»å·¥å…·ï¼ˆå¦‚baidu_searchã€web_searchç­‰ï¼‰ï¼šç”¨äºä¿¡æ¯æŸ¥è¯¢ã€çŸ¥è¯†è·å–
   - é€‚ç”¨ï¼šæŸ¥è¯¢äººç‰©ä¿¡æ¯ã€å†å²äº‹ä»¶ã€æ¦‚å¿µè§£é‡Šã€å®æ—¶ä¿¡æ¯ç­‰
   - é¦–é€‰ç”¨äºå›ç­”"è°æ˜¯XX"ã€"ä»€ä¹ˆæ˜¯XX"ã€"XXçš„ä¿¡æ¯"ç­‰æŸ¥è¯¢
3. å…¶ä»–å·¥å…·ï¼šæ ¹æ®å…·ä½“åŠŸèƒ½é€‰æ‹©ï¼Œç¡®ä¿å·¥å…·åŠŸèƒ½ä¸ç”¨æˆ·éœ€æ±‚åŒ¹é…

è¯·ç”ŸæˆJSONæ ¼å¼çš„æ‰§è¡Œè®¡åˆ’ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "steps": [
    {{
      "tool": "å·¥å…·åç§°",
      "purpose": "æ‰§è¡Œç›®çš„æè¿°",
      "dependencies": [ä¾èµ–çš„æ­¥éª¤ç´¢å¼•åˆ—è¡¨],
      "parameters": {{"å‚æ•°å": "å‚æ•°å€¼"}},
      "output_path": "ç»“æœå­—æ®µè·¯å¾„"
    }}
  ]
}}

æ³¨æ„äº‹é¡¹ï¼š
1. æ­¥éª¤ä¹‹é—´å¯èƒ½å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œç”¨dependencieså­—æ®µè¡¨ç¤º
2. output_pathç”¨äºä»å‰é¢æ­¥éª¤çš„ç»“æœä¸­æå–æ•°æ®ï¼Œä½¿ç”¨JMESPathè¯­æ³•ï¼š
   - æ ‡å‡†åšæ³•ï¼šä½¿ç”¨"data.primary"ï¼ˆæ‰€æœ‰å·¥å…·çš„ä¸»è¦è¾“å‡ºéƒ½åœ¨è¿™é‡Œï¼‰
   - ç‰¹æ®Šæƒ…å†µï¼šå¦‚éœ€å…¶ä»–æ•°æ®å¯ä½¿ç”¨"data.secondary.å­—æ®µå"æˆ–"message"
3. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å‚æ•°éƒ½æœ‰åˆé€‚çš„å€¼
4. å¦‚æœæŸ¥è¯¢å¾ˆç®€å•ï¼Œå¯ä»¥åªç”¨ä¸€ä¸ªæ­¥éª¤
5. ä¼˜å…ˆé€‰æ‹©æœ€é€‚åˆçš„å·¥å…·ï¼Œé¿å…è¿‡åº¦å¤æ‚åŒ–

é€šç”¨è®¾è®¡åŸåˆ™ï¼š
- æ‰€æœ‰å·¥å…·éƒ½éµå¾ªç»Ÿä¸€çš„è¾“å‡ºæ ¼å¼ï¼Œä¸»è¦æ•°æ®æ”¾åœ¨data.primaryå­—æ®µ
- ä¾èµ–æ­¥éª¤é€šå¸¸ä½¿ç”¨output_path: "data.primary"æå–ä¸Šä¸€æ­¥çš„ä¸»è¦è¾“å‡º
- ç³»ç»Ÿä¼šæ ¹æ®ç›®æ ‡å·¥å…·çš„å‚æ•°ç­¾åè‡ªåŠ¨è¿›è¡Œæ™ºèƒ½æ•°æ®æ˜ å°„
- å·¥å…·é—´çš„æ•°æ®ä¼ é€’å®Œå…¨åŸºäºæ ‡å‡†åŒ–çš„è¾“å‡ºç»“æ„ï¼Œæ— éœ€è€ƒè™‘å…·ä½“å·¥å…·ç‰¹æ€§
- ç”Ÿæˆå‚æ•°æ—¶å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ç›®æ ‡å·¥å…·çš„inputSchemaä¸­å®šä¹‰çš„å‚æ•°åä¸ç±»å‹ï¼Œå¡«å……æ‰€æœ‰requiredå‚æ•°ã€‚
- å¦‚æœä¾èµ–ä¸Šä¸€æ­¥çš„æ•°æ®ï¼Œè¯·ç›´æ¥å°†å…¶æ˜ å°„åˆ°ç›®æ ‡å·¥å…·çš„æ­£ç¡®å‚æ•°åï¼ˆä¾æ®inputSchemaï¼‰ã€‚
- è‹¥å¿…å¡«å‚æ•°ç¼ºå¤±ï¼Œè¯·å‚è€ƒ[å¯ç”¨é»˜è®¤ç¯å¢ƒæç¤º]ï¼ˆä¾‹å¦‚ bucket_name å¯ä½¿ç”¨ DEFAULT_BUCKET_NAMEï¼‰ï¼Œå¹¶åœ¨parametersä¸­è¡¥é½ã€‚

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è¯´æ˜æ–‡å­—ã€‚
"""
            
            # è°ƒç”¨LLMç”Ÿæˆè®¡åˆ’
            response = await self.llm.generate(prompt, max_tokens=2000)
            
            # è§£æJSONå“åº”
            try:
                # æ¸…ç†å“åº”ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                cleaned_response = response.strip()
                if cleaned_response.startswith('```json'):
                    cleaned_response = cleaned_response[7:]  # ç§»é™¤å¼€å¤´çš„```json
                if cleaned_response.startswith('```'):
                    cleaned_response = cleaned_response[3:]  # ç§»é™¤å¼€å¤´çš„```
                if cleaned_response.endswith('```'):
                    cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„```
                cleaned_response = cleaned_response.strip()
                
                self.logger.debug(f"æ¸…ç†åçš„å“åº”: {cleaned_response}")
                
                plan_data = json.loads(cleaned_response)
                steps = plan_data.get('steps', [])
                
                # éªŒè¯è®¡åˆ’
                if self._validate_plan(steps):
                    self.logger.info(f"æ‰§è¡Œè®¡åˆ’ç”ŸæˆæˆåŠŸï¼Œå…±{len(steps)}ä¸ªæ­¥éª¤")
                    return steps
                else:
                    self.logger.warning("ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’éªŒè¯å¤±è´¥")
                    return []
                    
            except json.JSONDecodeError as e:
                self.logger.error(f"è§£ææ‰§è¡Œè®¡åˆ’JSONå¤±è´¥: {e}")
                self.logger.debug(f"åŸå§‹LLMå“åº”: {response}")
                self.logger.debug(f"æ¸…ç†åå“åº”: {cleaned_response}")
                return []
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ‰§è¡Œè®¡åˆ’å¤±è´¥: {e}")
            return []
    
    def _format_tool_list(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨"""
        tool_list = self.tool_registry.get_tool_list()
        formatted_tools = []
        
        # å¤„ç†å·¥å…·åˆ—è¡¨ï¼Œæ”¯æŒåˆ—è¡¨å’Œå­—å…¸ä¸¤ç§æ ¼å¼
        if isinstance(tool_list, list):
            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼
            for tool_info in tool_list:
                tool_name = tool_info.get('name', 'æœªçŸ¥å·¥å…·')
                description = tool_info.get('description', 'æ— æè¿°')
                
                # å°è¯•ä»inputSchemaè·å–å‚æ•°ä¿¡æ¯
                parameters = tool_info.get('inputSchema', tool_info.get('parameters', {}))
                
                tool_desc = f"- {tool_name}: {description}"
                
                # æ·»åŠ å‚æ•°ä¿¡æ¯
                if parameters.get('properties'):
                    tool_desc += "\n  å‚æ•°:"
                    for param_name, param_info in parameters['properties'].items():
                        param_type = param_info.get('type', 'string')
                        param_desc = param_info.get('description', '')
                        required = param_name in parameters.get('required', [])
                        required_mark = "*" if required else ""
                        tool_desc += f"\n    - {param_name}{required_mark} ({param_type}): {param_desc}"
                
                formatted_tools.append(tool_desc)
        else:
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            for tool_name, tool_info in tool_list.items():
                description = tool_info.get('description', 'æ— æè¿°')
                parameters = tool_info.get('parameters', {})
                
                tool_desc = f"- {tool_name}: {description}"
                
                # æ·»åŠ å‚æ•°ä¿¡æ¯
                if parameters.get('properties'):
                    tool_desc += "\n  å‚æ•°:"
                    for param_name, param_info in parameters['properties'].items():
                        param_type = param_info.get('type', 'string')
                        param_desc = param_info.get('description', '')
                        required = param_name in parameters.get('required', [])
                        required_mark = "*" if required else ""
                        tool_desc += f"\n    - {param_name}{required_mark} ({param_type}): {param_desc}"
            
                formatted_tools.append(tool_desc)
        
        return "\n".join(formatted_tools)

    def _get_tools_definitions_for_prompt(self) -> List[dict]:
        """ä»¥JSONå¯åµŒå…¥å½¢å¼è¿”å›å·¥å…·å®šä¹‰ï¼ˆåŒ…å«ç²¾ç¡®çš„å…¥å‚ä¸è¾“å‡ºSchemaï¼‰ã€‚"""
        tools_for_prompt: List[Dict[str, Any]] = []
        try:
            tool_list = self.tool_registry.get_tool_list()
            if isinstance(tool_list, list):
                for tool in tool_list:
                    tools_for_prompt.append({
                        "name": tool.get("name"),
                        "description": tool.get("description", ""),
                        "inputSchema": tool.get("inputSchema", {
                            "type": "object", "properties": {}, "required": []
                        }),
                        "outputSchema": tool.get("outputSchema")
                    })
            else:
                for name, tool in tool_list.items():
                    tools_for_prompt.append({
                        "name": name,
                        "description": tool.get("description", ""),
                        "inputSchema": tool.get("parameters", {
                            "type": "object", "properties": {}, "required": []
                        }),
                        "outputSchema": tool.get("outputSchema")
                    })
        except Exception as e:
            self.logger.warning(f"è·å–å·¥å…·å®šä¹‰å¤±è´¥: {e}")
        return tools_for_prompt

    def _collect_non_sensitive_env_hints(self) -> Dict[str, Any]:
        """æ”¶é›†ç”¨äºLLMå¯¹é½çš„éæ•æ„Ÿç¯å¢ƒæç¤ºï¼Œä¾‹å¦‚é»˜è®¤bucket/endpointç­‰ï¼Œä¸åŒ…å«å¯†é’¥ã€‚"""
        hints: Dict[str, Any] = {}
        try:
            # éæ•æ„Ÿï¼šendpointã€é»˜è®¤bucketï¼ˆè‹¥å­˜åœ¨ï¼‰
            endpoint = os.getenv("MINIO_ENDPOINT")
            default_bucket = os.getenv("BUCKET_NAME") or os.getenv("DEFAULT_BUCKET_NAME")
            if endpoint:
                hints["MINIO_ENDPOINT"] = endpoint
            if default_bucket:
                hints["DEFAULT_BUCKET_NAME"] = default_bucket
        except Exception:
            pass
        return hints
    
    def _validate_plan(self, steps: List[dict]) -> bool:
        """éªŒè¯æ‰§è¡Œè®¡åˆ’"""
        if not steps or not isinstance(steps, list):
            return False
        
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        tool_list = self.tool_registry.get_tool_list()
        if isinstance(tool_list, list):
            available_tools = set(tool['name'] for tool in tool_list)
        else:
            available_tools = set(tool_list.keys())
        
        for i, step in enumerate(steps):
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not isinstance(step, dict):
                return False
            
            if 'tool' not in step:
                self.logger.warning(f"æ­¥éª¤{i}ç¼ºå°‘toolå­—æ®µ")
                return False
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
            tool_name = step['tool']
            if tool_name not in available_tools:
                self.logger.warning(f"æ­¥éª¤{i}ä½¿ç”¨äº†ä¸å­˜åœ¨çš„å·¥å…·: {tool_name}")
                return False
            
            # æ£€æŸ¥ä¾èµ–å…³ç³»
            dependencies = step.get('dependencies', [])
            if dependencies:
                for dep in dependencies:
                    if not isinstance(dep, int) or dep < 0 or dep >= i:
                        self.logger.warning(f"æ­¥éª¤{i}çš„ä¾èµ–å…³ç³»æ— æ•ˆ: {dep}")
                        return False
        
        return True
    
    async def _execute_plan(self, plan: List[dict], context: dict) -> dict:
        """æ‰§è¡Œè®¡åˆ’"""
        results = {}
        execution_steps = []
        
        for i, step in enumerate(plan):
            step_start_time = time.time()
            
            try:
                # å‘é€å·¥å…·å¼€å§‹æ‰§è¡Œæ¶ˆæ¯
                tool_name = step['tool']
                purpose = step.get('purpose', 'æ‰§è¡Œä¸­...')
                step_id = f"task_{tool_name}_{i}_{int(time.time())}"  # ç”Ÿæˆå”¯ä¸€çš„step_id
                
                await self._send_status_update("tool_start", 
                    tool_name=tool_name,
                    step_id=step_id,  # æ·»åŠ step_id
                    message=f"æ­£åœ¨æ‰§è¡Œ: {purpose}",
                    step_index=i,
                    total_steps=len(plan)
                )
                
                # è§£æä¾èµ–
                resolved_params = self._resolve_dependencies(step, results)
                
                # åˆå¹¶å‚æ•°
                final_params = {**step.get('parameters', {}), **resolved_params}

                # åŸºäºSchemaå¯¹é½ä¸æ ¡éªŒï¼ˆåŒ…å«ä¸€æ¬¡å¯é€‰çš„LLMçº æ­£ï¼‰ã€‚ä¸å†åšä»»ä½•æ¨¡å¼/è§„åˆ™è¡¥å…¨ã€‚
                self.logger.info(f"å‚æ•°å¯¹é½å‰: tool={step['tool']} raw_params_keys={list(final_params.keys())}")
                final_params = await self._align_parameters_with_schema(step['tool'], final_params, context)
                self.logger.info(f"å‚æ•°å¯¹é½å: tool={step['tool']} aligned_params={final_params}")
                
                self.logger.info(f"æ‰§è¡Œæ­¥éª¤{i+1}/{len(plan)}: {step['tool']}")
                
                # æ‰§è¡Œå·¥å…·
                result = await self.tool_executor.execute(
                    step['tool'],
                    final_params
                )
                # è®°å½•å·¥å…·è¿”å›çš„å…³é”®ä¿¡æ¯ï¼Œä¾¿äºå®šä½é”™è¯¯
                try:
                    status_dbg = result.get('status') if isinstance(result, dict) else 'unknown'
                    msg_dbg = result.get('message') if isinstance(result, dict) else ''
                    err_dbg = result.get('error') if isinstance(result, dict) else ''
                    self.logger.info(f"å·¥å…·è¿”å›æ‘˜è¦: tool={step['tool']} status={status_dbg} message={msg_dbg} error={err_dbg}")
                except Exception:
                    pass
                
                # åˆ¤æ–­æ‰§è¡ŒçŠ¶æ€
                step_status = 'success' if result and not isinstance(result, dict) or not result.get('error') else 'error'
                
                # è®°å½•æ‰§è¡Œæ­¥éª¤
                execution_step = {
                    'step_index': i,
                    'tool_name': step['tool'],
                    'purpose': step.get('purpose', ''),
                    'input_params': final_params,
                    'output': result,
                    'execution_time': time.time() - step_start_time,
                    'status': step_status
                }
                
                execution_steps.append(execution_step)
                
                # å‘é€å·¥å…·æ‰§è¡Œç»“æœæ¶ˆæ¯
                await self._send_status_update("tool_result", 
                    tool_name=tool_name,
                    step_id=step_id,  # ä½¿ç”¨ç›¸åŒçš„step_id
                    status=step_status,
                    execution_time=time.time() - step_start_time,
                    step_data=execution_step,
                    message=f"{tool_name}: {step_status}"
                )
                
                # å­˜å‚¨ç»“æœ
                results[str(i)] = {
                    'tool': step['tool'],
                    'input': final_params,
                    'output': result,
                    'status': execution_step['status']
                }
                
                self.logger.info(f"æ­¥éª¤{i+1}æ‰§è¡Œå®Œæˆ: {execution_step['status']}")
                
            except Exception as e:
                self.logger.error(f"æ­¥éª¤{i+1}æ‰§è¡Œå¤±è´¥: {e}")
                
                execution_step = {
                    'step_index': i,
                    'tool_name': step['tool'],
                    'purpose': step.get('purpose', ''),
                    'input_params': step.get('parameters', {}),
                    'output': None,
                    'execution_time': time.time() - step_start_time,
                    'status': 'error',
                    'error': str(e)
                }
                
                execution_steps.append(execution_step)
                
                # å‘é€å·¥å…·æ‰§è¡Œå¤±è´¥æ¶ˆæ¯
                await self._send_status_update("tool_result", 
                    tool_name=step['tool'],
                    step_id=step_id,  # ä½¿ç”¨ç›¸åŒçš„step_id
                    status='error',
                    execution_time=time.time() - step_start_time,
                    step_data=execution_step,
                    message=f"{step['tool']}: error - {str(e)}"
                )
                
                # å­˜å‚¨é”™è¯¯ç»“æœ
                results[str(i)] = {
                    'tool': step['tool'],
                    'input': step.get('parameters', {}),
                    'output': None,
                    'status': 'error',
                    'error': str(e)
                }
        
        # èšåˆç»“æœ
        return await self._aggregate_results(results, execution_steps)

    async def _align_parameters_with_schema(self, tool_name: str, params: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†å‚æ•°ä¸å·¥å…·çš„ inputSchema å¯¹é½ï¼š
        1) ä½¿ç”¨ inputSchema.properties ä½œä¸ºçœŸå€¼æ¥æºï¼Œé‡å‘½å/é‡æ˜ å°„æœªçŸ¥å‚æ•°åˆ°æœ€ä½³åŒ¹é…å‚æ•°
        2) æœ¬åœ°æ ¡éªŒ required ä¸ç±»å‹ï¼›è‹¥ä»å­˜åœ¨ç¼ºå¤±æˆ–æ˜æ˜¾ä¸åŒ¹é…ï¼Œè°ƒç”¨LLMè¿›è¡Œä¸€æ¬¡çº æ­£
        3) è¿”å›å¯¹é½åçš„å‚æ•°
        """
        tool_def = self._get_tool_definition(tool_name)
        if not tool_def:
            return params

        input_schema = tool_def.get('inputSchema') or {"type": "object", "properties": {}, "required": []}
        properties: Dict[str, Any] = input_schema.get('properties', {}) or {}
        required: List[str] = input_schema.get('required', []) or []
        try:
            self.logger.info(
                f"Schemaæ‘˜è¦: tool={tool_name} properties={list(properties.keys())} required={required} raw_params={params}"
            )
        except Exception:
            pass

        # 1) å·²çŸ¥/æœªçŸ¥é”®åˆ†ç¦»ï¼ˆæ— æ¨¡å¼åŒ¹é…ï¼‰
        normalized: Dict[str, Any] = {}
        unknown_params: Dict[str, Any] = {}
        for key, value in params.items():
            if key in properties:
                normalized[key] = value
            elif key != '__extracted_values':
                unknown_params[key] = value

        # å¤„ç†ä¾èµ–æå–çš„åŸå§‹å€¼ï¼ˆä¸åšæ¨¡å¼åŒ¹é…ï¼‰
        extracted_values = params.get('__extracted_values')

        # è‹¥æ°å¥½ç¼ºä¸€ä¸ªå¿…å¡«å‚æ•°ï¼Œå°è¯•ç”¨å•ä¸€æ¥æºå¡«å……ï¼ˆç¡®å®šæ€§è§„åˆ™ï¼‰
        missing_required_now = [r for r in required if r not in normalized]
        if len(missing_required_now) == 1:
            target_key = missing_required_now[0]
            # ä¼˜å…ˆä½¿ç”¨ extracted_values
            if extracted_values is not None:
                normalized[target_key] = extracted_values
                self.logger.info(f"ä½¿ç”¨ä¾èµ–è¾“å‡ºå¡«å……å”¯ä¸€å¿…å¡«å‚æ•°: {target_key}")
            # å…¶æ¬¡è‹¥åªæœ‰ä¸€ä¸ªæœªçŸ¥å‚æ•°ï¼Œä¹Ÿå¯ç¡®å®šæ€§èµ‹å€¼
            elif len(unknown_params) == 1:
                only_key, only_val = next(iter(unknown_params.items()))
                normalized[target_key] = only_val
                self.logger.info(f"ä½¿ç”¨å”¯ä¸€æœªçŸ¥å‚æ•°å¡«å……å¿…å¡«å‚æ•°: {target_key} <- {only_key}")
                unknown_params.pop(only_key, None)
        
        # å°†æœªçŸ¥å‚æ•°ä»¥è¾…åŠ©å­—æ®µä¼ é€’ï¼Œä¾›LLMå¯¹é½
        if unknown_params or extracted_values is not None:
            normalized['__unknown_params'] = unknown_params if unknown_params else {}
            if extracted_values is not None:
                normalized['__extracted_values'] = extracted_values

        # 2) æœ¬åœ°æ ¡éªŒä¸è½»é‡çº æ­£
        local_ok, local_fixed = self._validate_parameters_against_schema(properties, required, {k: v for k, v in normalized.items() if k in properties})
        if local_ok:
            # å¦‚æœè¿˜æœ‰æœªçŸ¥/æå–å€¼ï¼Œå°è¯•ç”¨LLMåšä¸€æ¬¡å‚æ•°å¹¶å…¥
            if normalized.get('__unknown_params') or normalized.get('__extracted_values'):
                try:
                    llm_fixed = await self._llm_refine_parameters(tool_def, normalized, context)
                    self.logger.info(f"LLMå¯¹é½è¾“å‡º(æˆªæ–­): tool={tool_name} raw={str(llm_fixed)[:400]}")
                    final_ok, final_params = self._validate_parameters_against_schema(properties, required, {k: v for k, v in llm_fixed.items() if k in properties})
                    if final_ok:
                        return final_params
                except Exception as e:
                    self.logger.warning(f"LLMå‚æ•°åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å¯¹é½: {e}")
            return local_fixed

        # 3) LLM ä¸€æ¬¡çº æ­£ï¼ˆä¸¥æ ¼æ§åˆ¶ï¼šåªåœ¨å¿…è¦æ—¶ä½¿ç”¨ï¼‰
        try:
            if self.llm and hasattr(self.llm, 'generate'):
                # ä¼ å…¥åŒ…å«æœªçŸ¥/æå–å€¼çš„ä¸Šä¸‹æ–‡è®©LLMå¯¹é½
                context_params = dict(normalized)
                context_params.update(local_fixed)
                llm_fixed = await self._llm_refine_parameters(tool_def, context_params, context)
                # å†æ¬¡æœ¬åœ°æ ¡éªŒ
                final_ok, final_params = self._validate_parameters_against_schema(properties, required, llm_fixed)
                if final_ok:
                    self.logger.info(f"å‚æ•°å·²é€šè¿‡LLMçº æ­£å¹¶å¯¹é½Schema: {tool_name}")
                    return final_params
                else:
                    # è®°å½•ç¼ºå¤±çš„å¿…å¡«é¡¹ä»¥ä¾¿å®šä½
                    missing_after = [r for r in required if r not in (final_params or {})]
                    self.logger.warning(f"LLMçº æ­£åä»æœªé€šè¿‡æœ¬åœ°æ ¡éªŒ: tool={tool_name} missing={missing_after}, ä½¿ç”¨æœ¬åœ°çº æ­£ç»“æœ")
                    return local_fixed
        except Exception as e:
            self.logger.warning(f"LLMå‚æ•°çº æ­£å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°çº æ­£ç»“æœ: {e}")

        return local_fixed

    def _get_tool_definition(self, tool_name: str) -> Optional[Dict[str, Any]]:
        """ä»å·¥å…·æ³¨å†Œè¡¨è·å–å•ä¸ªå·¥å…·çš„å®šä¹‰ï¼ˆå« input/output schema ä¸æè¿°ï¼‰ã€‚"""
        try:
            tool_list = self.tool_registry.get_tool_list()
            if isinstance(tool_list, list):
                for tool in tool_list:
                    if tool.get('name') == tool_name:
                        return {
                            'name': tool.get('name'),
                            'description': tool.get('description', ''),
                            'inputSchema': tool.get('inputSchema', {"type": "object", "properties": {}, "required": []}),
                            'outputSchema': tool.get('outputSchema')
                        }
            else:
                # å…¼å®¹å­—å…¸æ ¼å¼
                if tool_name in tool_list:
                    tool = tool_list[tool_name]
                    return {
                        'name': tool_name,
                        'description': tool.get('description', ''),
                        'inputSchema': tool.get('parameters', {"type": "object", "properties": {}, "required": []}),
                        'outputSchema': tool.get('outputSchema')
                    }
        except Exception as e:
            self.logger.warning(f"è·å–å·¥å…·å®šä¹‰å¤±è´¥: {e}")
        return None

    def _validate_parameters_against_schema(self, properties: Dict[str, Any], required: List[str], params: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:
        """è½»é‡çº§æœ¬åœ°æ ¡éªŒï¼šç¡®ä¿requiredå­˜åœ¨ã€ç±»å‹å¤§è‡´åŒ¹é…ï¼Œå¹¶å°è¯•ç®€å•ç±»å‹çº æ­£ã€‚"""
        fixed = dict(params)
        # æ£€æŸ¥å¿…å¡«
        missing = [r for r in required if r not in fixed]
        # ç±»å‹æ ¡éªŒä¸ç®€å•çº æ­£
        for name, prop in (properties or {}).items():
            if name not in fixed:
                continue
            expected_type = (prop or {}).get('type')
            value = fixed[name]
            try:
                if expected_type == 'integer' and isinstance(value, str) and value.isdigit():
                    fixed[name] = int(value)
                elif expected_type == 'number' and isinstance(value, str):
                    try:
                        fixed[name] = float(value)
                    except Exception:
                        pass
                elif expected_type == 'array' and isinstance(value, str):
                    # å°è¯•è§£æJSONæ•°ç»„æ ¼å¼
                    try:
                        if value.strip().startswith('[') and value.strip().endswith(']'):
                            # å°è¯•å®‰å…¨è§£æJSON/Pythonæ•°ç»„æ ¼å¼
                            parsed = ast.literal_eval(value.strip())
                            if isinstance(parsed, (list, tuple)):
                                fixed[name] = list(parsed)
                            else:
                                # å›é€€åˆ°é€—å·åˆ†å‰²
                                fixed[name] = [v.strip() for v in value.split(',') if v.strip()]
                        else:
                            # é€—å·åˆ†å‰²
                            fixed[name] = [v.strip() for v in value.split(',') if v.strip()]
                    except (ValueError, SyntaxError):
                        # è§£æå¤±è´¥ï¼Œå›é€€åˆ°é€—å·åˆ†å‰²
                        fixed[name] = [v.strip() for v in value.split(',') if v.strip()]
                elif expected_type == 'boolean' and isinstance(value, str):
                    lowered = value.strip().lower()
                    if lowered in ['true', '1', 'yes', 'y']:
                        fixed[name] = True
                    elif lowered in ['false', '0', 'no', 'n']:
                        fixed[name] = False
            except Exception:
                # ä¿æŒåŸå€¼ï¼Œäº¤ç»™åç»­LLMæˆ–å·¥å…·è‡ªèº«æŠ¥é”™
                pass

        # å†æ¬¡è®¡ç®—ç¼ºå¤±
        missing = [r for r in required if r not in fixed]
        if missing:
            return False, fixed
        return True, fixed

    async def _llm_refine_parameters(self, tool_def: Dict[str, Any], params: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMæ ¹æ® inputSchema çº æ­£å‚æ•°ã€‚ä¸¥æ ¼è¦æ±‚åªè¿”å›JSONå¯¹è±¡ï¼ˆå‚æ•°å­—å…¸ï¼‰ï¼Œé”®å¿…é¡»ä¸ºinputSchema.propertiesä¸­å®šä¹‰çš„é”®ã€‚
        """
        name = tool_def.get('name')
        description = tool_def.get('description', '')
        input_schema = tool_def.get('inputSchema', {"type": "object", "properties": {}, "required": []})
        env_hints = self._collect_non_sensitive_env_hints()
        prompt = f"""
ä½ æ˜¯å‚æ•°æ˜ å°„ä¸æ ¡éªŒåŠ©æ‰‹ã€‚ç›®æ ‡æ˜¯ä¸ºå·¥å…·"{name}" ç”Ÿæˆä¸å…¶ inputSchema å®Œå…¨ä¸€è‡´çš„å‚æ•°å­—å…¸ã€‚

[å·¥å…·æè¿°]
{description}

[inputSchema]
{json.dumps(input_schema, ensure_ascii=False, indent=2)}

[å½“å‰å‚æ•°]
{json.dumps(params, ensure_ascii=False, indent=2)}

[ç¯å¢ƒæç¤ºï¼ˆéæ•æ„Ÿï¼Œä»…ä¾›å‚è€ƒï¼‰]
{json.dumps(env_hints, ensure_ascii=False, indent=2)}

æ³¨æ„ï¼š
- ä»…è¾“å‡ºJSONå¯¹è±¡ï¼Œä¸è¦ä»»ä½•è¯´æ˜æ–‡å­—ï¼›
- é”®åå¿…é¡»ä¸¥æ ¼æ¥è‡ª inputSchema.properties çš„é”®ï¼Œä¸èƒ½å¼•å…¥æ–°é”®ï¼›
- è‹¥å­˜åœ¨è¾…åŠ©å­—æ®µå¦‚ "__unknown_params"ã€"__extracted_values"ï¼Œè¯·ä»…å°†å…¶ä½œä¸ºå‚è€ƒï¼Œå°†å…¶ä¸­çš„å€¼åˆç†å½’å¹¶è¿› Schema å®šä¹‰çš„é”®ï¼›
- è‹¥ç¡®å®æ— æ³•æä¾›æŸå¿…å¡«å€¼ï¼Œå¯ç•™ç©ºå­—ç¬¦ä¸²ã€ç©ºæ•°ç»„æˆ– nullï¼›
- ä¸¥æ ¼ç¬¦åˆJSONæ ¼å¼ã€‚
"""
        try:
            response = await self.llm.generate(prompt, max_tokens=400, temperature=0.0)
            cleaned = response.strip()
            if cleaned.startswith('```json'):
                cleaned = cleaned[7:]
            if cleaned.startswith('```'):
                cleaned = cleaned[3:]
            if cleaned.endswith('```'):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            fixed = json.loads(cleaned)
            if isinstance(fixed, dict):
                return fixed
        except Exception as e:
            self.logger.warning(f"LLMå‚æ•°çº æ­£è§£æå¤±è´¥: {e}")
        return params
    
    def _resolve_dependencies(self, step: dict, results: dict) -> dict:
        """è§£æä¾èµ–å…³ç³»ï¼ˆæ— æ¨¡å¼åŒ¹é…ï¼‰ï¼š
        - ä¼˜å…ˆç”±LLMåœ¨plançš„parametersé‡Œç»™å‡ºæ­£ç¡®å‚æ•°ï¼›
        - è‹¥å­˜åœ¨ä¾èµ–ï¼Œä»…åœ¨"ç›®æ ‡å·¥å…·æ°å¥½ç¼ºå°‘ä¸”åªæœ‰ä¸€ä¸ªå¿…å¡«å‚æ•°"æ—¶ï¼Œç›´æ¥å°†æå–å€¼èµ‹ç»™è¯¥å‚æ•°ï¼›
        - å…¶ä»–æƒ…å†µå°†åŸå§‹ä¾èµ–å€¼æ”¾å…¥ä¿ç•™é”® '__extracted_values'ï¼Œä¾›åç»­ LLM å‚æ•°å¯¹é½é˜¶æ®µä½¿ç”¨ã€‚
        """
        resolved: Dict[str, Any] = {}
        dependencies = step.get('dependencies', [])
        if not dependencies:
            return resolved

        # å‡†å¤‡å·¥å…·schemaä¿¡æ¯
        tool_name = step.get('tool', '')
        tool_def = self._get_tool_definition(tool_name) or {}
        input_schema = tool_def.get('inputSchema') or {"type": "object", "properties": {}, "required": []}
        properties: Dict[str, Any] = input_schema.get('properties', {}) or {}
        required: List[str] = input_schema.get('required', []) or []

        extracted_values: List[Any] = []

        for dep_index in dependencies:
            dep_result = results.get(str(dep_index), {})
            dep_output = dep_result.get('output', {})

            # ä½¿ç”¨output_pathæå–ç‰¹å®šæ•°æ®
            output_path = step.get('output_path')
            if output_path:
                # JsonPath å‰ç¼€è½¬ JMESPath
                if output_path.startswith('$.'):
                    output_path = output_path[2:]
                    self.logger.info(f"å°†JsonPathè¯­æ³• '{step['output_path']}' è½¬æ¢ä¸ºJMESPathè¯­æ³• '{output_path}'")
                elif output_path.startswith('$'):
                    output_path = output_path[1:]
                    self.logger.info(f"å°†JsonPathè¯­æ³• '{step['output_path']}' è½¬æ¢ä¸ºJMESPathè¯­æ³• '{output_path}'")
                try:
                    value = jmespath.search(output_path, dep_output)
                except Exception as e:
                    self.logger.warning(f"æå–ä¾èµ–æ•°æ®å¤±è´¥ï¼Œè·¯å¾„: '{output_path}', é”™è¯¯: {e}")
                    value = None
            else:
                # é»˜è®¤ data.primary
                value = dep_output.get('data', {}).get('primary') if isinstance(dep_output, dict) else None

            if value is not None:
                extracted_values.append(value)

        if not extracted_values:
            return resolved

        # ä»…å½“"æ°å¥½ç¼ºä¸€ä¸ªå¿…å¡«å‚æ•°"æ—¶ï¼Œç›´æ¥èµ‹å€¼ï¼ˆç¡®å®šæ€§è§„åˆ™ï¼Œæ— æ¨¡å¼åŒ¹é…ï¼‰
        existing_keys = set((step.get('parameters') or {}).keys()) | set(resolved.keys())
        missing_required = [r for r in required if r not in existing_keys]
        if len(missing_required) == 1:
            resolved[missing_required[0]] = extracted_values[0] if len(extracted_values) == 1 else extracted_values
            self.logger.info(f"å°†ä¾èµ–è¾“å‡ºèµ‹ç»™å”¯ä¸€ç¼ºå¤±çš„å¿…å¡«å‚æ•°: {missing_required[0]}")
        else:
            # äº¤ç”±åç»­ LLM é˜¶æ®µå¯¹é½
            resolved['__extracted_values'] = extracted_values
            self.logger.info("å·²æ”¶é›†ä¾èµ–è¾“å‡ºï¼Œäº¤ç”±LLMåœ¨å‚æ•°å¯¹é½é˜¶æ®µå¤„ç†")

        return resolved
     
    def _get_tool_parameter_info(self, tool_name: str) -> dict:
        """å…¼å®¹æ–¹æ³•ï¼šè¿”å› inputSchema.propertiesã€‚"""
        try:
            tool_def = self._get_tool_definition(tool_name)
            if not tool_def:
                return {}
            schema = tool_def.get('inputSchema') or {}
            return (schema.get('properties') or {}) if isinstance(schema, dict) else {}
        except Exception as e:
            self.logger.warning(f"è·å–å·¥å…·å‚æ•°ä¿¡æ¯å¤±è´¥: {e}")
        return {}
    
    async def _aggregate_results(self, results: dict, execution_steps: List[dict]) -> dict:
        """èšåˆæ‰§è¡Œç»“æœ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        has_errors = any(step['status'] == 'error' for step in execution_steps)
        
        # æ™ºèƒ½å¤„ç†ç»“æœï¼Œæå–æœ‰ä»·å€¼çš„ä¿¡æ¯
        final_output = await self._extract_meaningful_output(execution_steps)
        
        if not final_output:
            if has_errors:
                final_output = "ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‰§è¡Œæ­¥éª¤è¯¦æƒ…ã€‚"
            else:
                final_output = "ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆè¾“å‡ºã€‚"
        
        return {
            "success": not has_errors,
            "final_output": final_output,
            "execution_steps": execution_steps,
            "step_count": len(execution_steps),
            "error_count": sum(1 for step in execution_steps if step['status'] == 'error')
        }
    
    async def _extract_meaningful_output(self, execution_steps: List[dict]) -> str:
        """ä»æ‰§è¡Œæ­¥éª¤ä¸­æå–æœ‰æ„ä¹‰çš„è¾“å‡º"""
        
        # è·å–æœ€åä¸€ä¸ªæˆåŠŸæ­¥éª¤
        last_successful_step = None
        for step in reversed(execution_steps):
            if step['status'] == 'success' and step.get('output'):
                last_successful_step = step
                break
        
        if not last_successful_step:
            return ""
        
        tool_name = last_successful_step.get('tool_name', '')
        output = last_successful_step.get('output', {})
        input_params = last_successful_step.get('input_params', {})
        
        # é¦–å…ˆå°è¯•é€šç”¨æ ¼å¼åŒ–
        formatted_result = self._format_tool_output(output, tool_name, input_params)
        
        # å¦‚æœç»“æœåŒ…å«ä¸°å¯Œçš„æ•°æ®ä¸”æœ‰LLMï¼Œä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“
        if self._should_use_llm_summary(output, formatted_result):
            try:
                llm_summary = await self._generate_llm_summary(output, input_params, tool_name)
                if llm_summary:
                    # å¯¹LLMæ€»ç»“ç»“æœä¹Ÿåº”ç”¨é“¾æ¥ä¼˜åŒ–
                    return self._format_output_with_links(llm_summary)
            except Exception as e:
                self.logger.warning(f"LLMæ€»ç»“å¤±è´¥ï¼Œä½¿ç”¨æ ¼å¼åŒ–ç»“æœ: {e}")
        
        # å¯¹æ ¼å¼åŒ–ç»“æœåº”ç”¨é“¾æ¥ä¼˜åŒ–
        return self._format_output_with_links(formatted_result)
    
    def _should_use_llm_summary(self, output: dict, formatted_result: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨LLMè¿›è¡Œæ€»ç»“"""
        # æ£€æŸ¥æ˜¯å¦æœ‰LLMå®¢æˆ·ç«¯å¯ç”¨
        has_llm = self.llm and hasattr(self.llm, 'generate')
        if not has_llm:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸°å¯Œçš„æ•°æ®ç»“æ„
        has_rich_data = (
            'data' in output and 'primary' in output.get('data', {}) and 
            isinstance(output['data']['primary'], list) and 
            len(output['data']['primary']) > 0
        )
        
        return has_rich_data
    
    async def _generate_llm_summary(self, output: dict, input_params: dict, tool_name: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ€»ç»“ - æ”¯æŒæµå¼è¾“å‡º"""
        try:
            # æå–ç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢
            user_query = input_params.get('query', '')
            
            # æå–æœç´¢ç»“æœæ•°æ®
            search_results = []
            if 'data' in output and 'primary' in output['data']:
                for item in output['data']['primary'][:3]:  # åªå–å‰3ä¸ªç»“æœ
                    if isinstance(item, dict):
                        title = item.get('title', '')
                        snippet = item.get('snippet', item.get('description', ''))
                        if title and snippet:
                            search_results.append({
                                'title': self._clean_text(title)[:600],  # é™åˆ¶é•¿åº¦
                                'content': self._clean_text(snippet)[:600]
                            })
            
            if not search_results:
                return ""
            
            # æ„å»ºé€šç”¨çš„æ™ºèƒ½æ€»ç»“æç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æå–ä¸“å®¶ï¼Œéœ€è¦ä»æœç´¢ç»“æœä¸­ä¸ºç”¨æˆ·æŸ¥è¯¢"{user_query}"æä¾›ç²¾å‡†ã€ç®€æ´çš„å›ç­”ã€‚

æœç´¢ç»“æœï¼š
"""
            
            for i, result in enumerate(search_results, 1):
                prompt += f"{i}. {result['title']}\n   {result['content']}\n\n"
            
            prompt += f"""
ä»»åŠ¡è¦æ±‚ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·æŸ¥è¯¢"{user_query}"çš„æ ¸å¿ƒéœ€æ±‚
2. ä»æœç´¢ç»“æœä¸­æå–æœ€ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„å…³é”®ä¿¡æ¯
3. è¿‡æ»¤æ‰é‡å¤ã€å†—ä½™ã€æ— å…³çš„å†…å®¹
4. ç”Ÿæˆä¸€ä¸ªç»“æ„æ¸…æ™°ã€è¯­è¨€æµç•…çš„å®Œæ•´å›ç­”ï¼ˆ300-600å­—ï¼‰

å›ç­”åŸåˆ™ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œçªå‡ºæ ¸å¿ƒä¿¡æ¯
- æä¾›å®Œæ•´çš„èƒŒæ™¯ä¿¡æ¯å’Œå…³é”®ç»†èŠ‚
- åŒ…å«å…·ä½“çš„æ•°å€¼ã€æ—¶é—´ã€åœ°ç‚¹ç­‰å…³é”®æ•°æ®
- ç¡®ä¿ä¿¡æ¯å®Œæ•´æ€§ï¼Œé¿å…çªç„¶æˆªæ–­
- å¦‚æœæ˜¯äººç‰©æŸ¥è¯¢ï¼ŒåŒ…å«ç”Ÿå¹³ã€ä¸»è¦æˆå°±ã€å†å²åœ°ä½ç­‰
- å¦‚æœæ˜¯æ¦‚å¿µæŸ¥è¯¢ï¼ŒåŒ…å«å®šä¹‰ã€åŸç†ã€åº”ç”¨ç­‰
- è¯­è¨€ç®€æ´æ˜äº†ï¼Œä½†ä¿¡æ¯è¦å……åˆ†å®Œæ•´
- ä¸è¦è¯´"æ ¹æ®æœç´¢ç»“æœ"ä¹‹ç±»çš„å¥—è¯

è¯·æä¾›å®Œæ•´è€Œè¯¦ç»†çš„å›ç­”ï¼š
"""
            
            # ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨æµå¼ç”Ÿæˆ
            if hasattr(self.llm, 'generate_streaming'):
                try:
                    messages = [{"role": "user", "content": prompt}]
                    content_buffer = ""
                    
                    # å‘é€ä»»åŠ¡æµå¼ç”Ÿæˆå¼€å§‹çŠ¶æ€
                    await self._send_status_update("task_streaming", 
                        message="æ­£åœ¨ç”Ÿæˆä»»åŠ¡æ€»ç»“...",
                        partial_content="",
                        accumulated_content=""
                    )
                    
                    # æµå¼ç”Ÿæˆä»»åŠ¡æ€»ç»“
                    async for chunk in self.llm.generate_streaming(messages, max_tokens=600, temperature=0.3):
                        if chunk.get('type') == 'content':
                            content = chunk.get('content', '')
                            content_buffer += content
                            
                            # å‘é€ä»»åŠ¡æµå¼å†…å®¹æ›´æ–°
                            await self._send_status_update("task_streaming", 
                                message=f"ç”Ÿæˆä¸­: {content_buffer}",
                                partial_content=content,
                                accumulated_content=content_buffer
                            )
                    
                    if content_buffer.strip():
                        return content_buffer.strip()
                        
                except Exception as e:
                    self.logger.warning(f"ä»»åŠ¡æµå¼æ€»ç»“å¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ–¹æ³•: {e}")
            
            # å›é€€åˆ°åŒæ­¥æ–¹æ³•
            response = await self.llm.generate(prompt, max_tokens=600, temperature=0.3)
            
            if response and len(response.strip()) > 10:
                # æ£€æŸ¥å›ç­”æ˜¯å¦è¢«æˆªæ–­
                if self._is_response_truncated(response):
                    self.logger.warning("æ£€æµ‹åˆ°LLMå›ç­”å¯èƒ½è¢«æˆªæ–­ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ")
                    # å°è¯•ç”¨æ›´é«˜çš„tokené™åˆ¶é‡æ–°ç”Ÿæˆ
                    extended_response = await self.llm.generate(prompt, max_tokens=600, temperature=0.3)
                    if extended_response and len(extended_response.strip()) > len(response.strip()):
                        return extended_response.strip()
                
                return response.strip()
            
        except Exception as e:
            self.logger.warning(f"LLMæ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
        
        return ""
    
    def _format_tool_output(self, output: dict, tool_name: str = "", input_params: dict = None) -> str:
        """é€šç”¨çš„å·¥å…·è¾“å‡ºæ ¼å¼åŒ–"""
        if input_params is None:
            input_params = {}
            
        try:
            # 1. ä¼˜å…ˆå¤„ç†ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚data.primaryç­‰ï¼‰ï¼Œé¿å…è¢«é€šç”¨messageé®è”½
            structured_result = self._extract_structured_result(output, input_params)
            if structured_result:
                return structured_result

            # 2. å…¶æ¬¡å°è¯•æå–ç›´æ¥çš„æ–‡æœ¬ç»“æœï¼ˆè·³è¿‡é€šç”¨çŠ¶æ€æ¶ˆæ¯ï¼‰
            direct_result = self._extract_direct_result(output)
            if direct_result and not self._is_generic_message(direct_result):
                return direct_result
            
            # 3. å¦‚æœæ˜¯åˆ—è¡¨æ•°æ®ï¼Œæ ¼å¼åŒ–ä¸ºæ‘˜è¦
            list_result = self._extract_list_result(output)
            if list_result:
                return list_result
            
            # 4. æœ€åå…œåº•ï¼šè¿”å›ç®€åŒ–çš„JSONæˆ–æ›´å‹å¥½çš„å®Œæˆæç¤º
            return self._extract_fallback_result(output, direct_result)
            
        except Exception as e:
            self.logger.warning(f"æ ¼å¼åŒ–å·¥å…·è¾“å‡ºå¤±è´¥: {e}")
            return "ä»»åŠ¡æ‰§è¡Œå®Œæˆã€‚"
    
    def _is_generic_message(self, message: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯é€šç”¨çš„çŠ¶æ€æ¶ˆæ¯"""
        generic_patterns = [
            r'æœç´¢æˆåŠŸ.*æ‰¾åˆ°.*ç»“æœ',
            r'.*æ‰§è¡Œå®Œæˆ',
            r'.*æˆåŠŸ',
            r'ä»»åŠ¡.*å®Œæˆ'
        ]
        
        message_lower = message.lower()
        return any(re.search(pattern, message_lower) for pattern in generic_patterns)
    
    def _extract_direct_result(self, output: dict) -> str:
        """æå–ç›´æ¥çš„æ–‡æœ¬ç»“æœ"""
        # ä¼˜å…ˆçº§é¡ºåºï¼šmessage > result(string) > content
        for key in ['message', 'content']:
            if key in output and isinstance(output[key], str) and output[key].strip():
                return output[key].strip()
        
        # æ£€æŸ¥resultå­—æ®µ
        if 'result' in output:
            result = output['result']
            if isinstance(result, str) and result.strip():
                return result.strip()
        
        return ""
    
    def _extract_structured_result(self, output: dict, input_params: dict = None) -> str:
        """æå–ç»“æ„åŒ–æ•°æ®ç»“æœ"""
        if input_params is None:
            input_params = {}
        
        # ä¼˜å…ˆå¤„ç†é€šç”¨çš„ä¸‹è½½é“¾æ¥å­—æ®µ
        download_result = self._extract_download_links(output)
        if download_result:
            return download_result
            
        # å¤„ç†åŒ…å«dataå­—æ®µçš„å¤æ‚ç»“æ„
        if 'data' in output and isinstance(output['data'], dict):
            data = output['data']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰primaryæ•°æ®ï¼ˆé€šå¸¸æ˜¯æœç´¢ç»“æœï¼‰
            if 'primary' in data and isinstance(data['primary'], list):
                return self._format_search_results_intelligently(data['primary'], data, input_params)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æœ‰æ„ä¹‰çš„æ•°æ®å­—æ®µ
            for key in ['results', 'items', 'entries', 'content']:
                if key in data and isinstance(data[key], (list, dict)):
                    return self._format_data_field(data[key], key)
        
        # å¤„ç†ç›´æ¥åŒ…å«resultsçš„æƒ…å†µ
        if 'result' in output and isinstance(output['result'], dict):
            result_dict = output['result']
            # å¯»æ‰¾æ–‡æœ¬å­—æ®µ
            for text_key in ['text', 'content', 'description', 'summary', 'answer']:
                if text_key in result_dict and isinstance(result_dict[text_key], str):
                    return result_dict[text_key].strip()
        
        return ""
    
    def _extract_download_links(self, output: dict) -> str:
        """é€šç”¨çš„ä¸‹è½½é“¾æ¥æå–é€»è¾‘"""
        download_links = []
        
        # æ£€æŸ¥ data.primary ä¸­çš„ä¸‹è½½é“¾æ¥ï¼ˆä¼˜å…ˆï¼‰
        if 'data' in output and isinstance(output['data'], dict):
            primary = output['data'].get('primary')
            if primary:
                if isinstance(primary, list):
                    # åˆ—è¡¨æ ¼å¼ï¼šå¤šä¸ªæ–‡ä»¶
                    for item in primary:
                        if isinstance(item, dict) and item.get('download_url'):
                            download_links.append(item)
                elif isinstance(primary, dict) and primary.get('download_url'):
                    # å•ä¸ªæ–‡ä»¶
                    download_links.append(primary)
        
        # æ£€æŸ¥é¡¶å±‚çš„ download_url
        if not download_links and output.get('download_url'):
            download_links.append(output)
        
        # æ£€æŸ¥ results ä¸­çš„ä¸‹è½½é“¾æ¥
        if not download_links and 'results' in output and isinstance(output['results'], list):
            for item in output['results']:
                if isinstance(item, dict) and item.get('download_url'):
                    download_links.append(item)
        
        if not download_links:
            return ""
        
        return self._format_download_links(download_links)
    
    def _format_download_links(self, download_links: list) -> str:
        """æ ¼å¼åŒ–ä¸‹è½½é“¾æ¥ä¿¡æ¯ä¸ºMarkdowné“¾æ¥æ ¼å¼"""
        if not download_links:
            return ""
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(download_links)
        
        # æ„å»ºæ¶ˆæ¯
        message_parts = []
        
        if total_count == 1:
            link_info = download_links[0]
            file_name = link_info.get('name') or link_info.get('original_name') or link_info.get('file_name') or 'æ–‡ä»¶'
            download_url = link_info.get('download_url')
            expires_in = link_info.get('expires_in_seconds', 0)
            
            # è·å–æ–‡ä»¶å›¾æ ‡
            file_icon = self._get_file_icon(file_name)
            
            message_parts.append(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
            message_parts.append("")
            message_parts.append(f"ğŸ“„ æ–‡ä»¶åˆ—è¡¨:")
            # ä½¿ç”¨Markdowné“¾æ¥æ ¼å¼ï¼š[æ–‡ä»¶å](ä¸‹è½½é“¾æ¥)
            message_parts.append(f"1. {file_icon} [{file_name}]({download_url})")
            
            if expires_in > 0:
                time_str = self._format_expiry_time(expires_in)
                message_parts.append(f"   â° æœ‰æ•ˆæœŸ: {time_str}")
        else:
            message_parts.append(f"âœ… æˆåŠŸä¸Šä¼  {total_count} ä¸ªæ–‡ä»¶")
            message_parts.append("")
            message_parts.append("ğŸ“ æ–‡ä»¶åˆ—è¡¨:")
            
            for i, link_info in enumerate(download_links, 1):
                file_name = link_info.get('name') or link_info.get('original_name') or link_info.get('file_name') or f'æ–‡ä»¶_{i}'
                download_url = link_info.get('download_url')
                expires_in = link_info.get('expires_in_seconds', 0)
                
                # è·å–æ–‡ä»¶å›¾æ ‡
                file_icon = self._get_file_icon(file_name)
                
                # ä½¿ç”¨Markdowné“¾æ¥æ ¼å¼
                message_parts.append(f"{i}. {file_icon} [{file_name}]({download_url})")
                
                if expires_in > 0:
                    time_str = self._format_expiry_time(expires_in)
                    message_parts.append(f"   â° æœ‰æ•ˆæœŸ: {time_str}")
        
        return "\n".join(message_parts)
    
    def _get_file_icon(self, file_name: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›å¯¹åº”çš„å›¾æ ‡"""
        if not file_name:
            return "ğŸ“„"
        
        # è·å–æ–‡ä»¶æ‰©å±•å
        extension = file_name.lower().split('.')[-1] if '.' in file_name else ''
        
        # æ–‡ä»¶ç±»å‹å›¾æ ‡æ˜ å°„
        icon_mapping = {
            # å›¾ç‰‡æ–‡ä»¶
            'jpg': 'ğŸ–¼ï¸', 'jpeg': 'ğŸ–¼ï¸', 'png': 'ğŸ–¼ï¸', 'gif': 'ğŸ–¼ï¸', 'bmp': 'ğŸ–¼ï¸', 
            'svg': 'ğŸ–¼ï¸', 'webp': 'ğŸ–¼ï¸', 'ico': 'ğŸ–¼ï¸', 'tiff': 'ğŸ–¼ï¸', 'tif': 'ğŸ–¼ï¸',
            
            # æ–‡æ¡£æ–‡ä»¶
            'pdf': 'ğŸ“•', 'doc': 'ğŸ“˜', 'docx': 'ğŸ“˜', 'xls': 'ğŸ“—', 'xlsx': 'ğŸ“—',
            'ppt': 'ğŸ“™', 'pptx': 'ğŸ“™', 'txt': 'ğŸ“„', 'rtf': 'ğŸ“„',
            
            # ä»£ç æ–‡ä»¶
            'js': 'ğŸ“œ', 'ts': 'ğŸ“œ', 'py': 'ğŸ“œ', 'java': 'ğŸ“œ', 'cpp': 'ğŸ“œ', 
            'c': 'ğŸ“œ', 'html': 'ğŸ“œ', 'css': 'ğŸ“œ', 'json': 'ğŸ“œ', 'xml': 'ğŸ“œ',
            'sql': 'ğŸ“œ', 'sh': 'ğŸ“œ', 'bat': 'ğŸ“œ', 'php': 'ğŸ“œ', 'rb': 'ğŸ“œ',
            
            # å‹ç¼©æ–‡ä»¶
            'zip': 'ğŸ—œï¸', 'rar': 'ğŸ—œï¸', '7z': 'ğŸ—œï¸', 'tar': 'ğŸ—œï¸', 'gz': 'ğŸ—œï¸',
            'bz2': 'ğŸ—œï¸', 'xz': 'ğŸ—œï¸',
            
            # éŸ³é¢‘æ–‡ä»¶
            'mp3': 'ğŸµ', 'wav': 'ğŸµ', 'flac': 'ğŸµ', 'aac': 'ğŸµ', 'ogg': 'ğŸµ',
            'wma': 'ğŸµ', 'm4a': 'ğŸµ',
            
            # è§†é¢‘æ–‡ä»¶
            'mp4': 'ğŸ¬', 'avi': 'ğŸ¬', 'mkv': 'ğŸ¬', 'mov': 'ğŸ¬', 'wmv': 'ğŸ¬',
            'flv': 'ğŸ¬', 'webm': 'ğŸ¬', 'm4v': 'ğŸ¬',
            
            # å…¶ä»–å¸¸è§æ ¼å¼
            'csv': 'ğŸ“Š', 'log': 'ğŸ“', 'md': 'ğŸ“‹', 'yml': 'âš™ï¸', 'yaml': 'âš™ï¸',
            'ini': 'âš™ï¸', 'conf': 'âš™ï¸', 'cfg': 'âš™ï¸'
        }
        
        return icon_mapping.get(extension, 'ğŸ“„')  # é»˜è®¤æ–‡æ¡£å›¾æ ‡
    
    def _format_expiry_time(self, expires_in_seconds: int) -> str:
        """æ ¼å¼åŒ–è¿‡æœŸæ—¶é—´"""
        if expires_in_seconds <= 0:
            return "æ°¸ä¹…"
        
        hours = expires_in_seconds // 3600
        minutes = (expires_in_seconds % 3600) // 60
        
        if hours > 24:
            days = hours // 24
            return f"{days}å¤©"
        elif hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
        else:
            return f"{minutes}åˆ†é’Ÿ"
    
    def _format_search_results_intelligently(self, primary_data: list, context: dict, input_params: dict) -> str:
        """æ™ºèƒ½æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not primary_data:
            return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
        
        user_query = input_params.get('query', '')
        
        # é€šç”¨æ ¼å¼åŒ–ï¼šåŸºäºæ•°æ®ç±»å‹è€Œéå…·ä½“ç”¨é€”
        return self._format_primary_data_universally(primary_data, context, user_query)
    
    def _format_primary_data_universally(self, primary_data: list, context: dict, user_query: str) -> str:
        """é€šç”¨çš„ä¸»è¦æ•°æ®æ ¼å¼åŒ–"""
        if not primary_data:
            return "æ²¡æœ‰ç”Ÿæˆæ•°æ®ã€‚"
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        counts = context.get('counts', {})
        total = counts.get('total', len(primary_data))
        successful = counts.get('successful', len(primary_data))
        failed = counts.get('failed', 0)
        
        # åŸºäºæ•°æ®ç±»å‹è¿›è¡Œé€šç”¨æ ¼å¼åŒ–
        if isinstance(primary_data[0], str):
            return self._format_string_list(primary_data, counts, total, successful, failed)
        elif isinstance(primary_data[0], dict):
            return self._format_dict_list(primary_data, counts, total, successful, failed)
        else:
            return f"å¤„ç†å®Œæˆï¼Œç”Ÿæˆäº† {len(primary_data)} é¡¹æ•°æ®ã€‚"
    
    def _format_string_list(self, strings: list, counts: dict, total: int, successful: int, failed: int) -> str:
        """æ ¼å¼åŒ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆURLã€æ–‡ä»¶è·¯å¾„ç­‰ï¼‰"""
        if len(strings) == 1:
            return f"å¤„ç†å®Œæˆï¼ç»“æœï¼š{strings[0]}"
        
        # æ„å»ºç»Ÿè®¡ä¿¡æ¯
        stats = f"å¤„ç†å®Œæˆï¼Œå…± {successful} é¡¹"
        if failed > 0:
            stats += f"ï¼ˆå¤±è´¥ {failed} é¡¹ï¼‰"
        
        # æ˜¾ç¤ºå‰å‡ é¡¹ç»“æœ
        display_count = min(3, len(strings))
        result_list = "\n".join(f"{i+1}. {strings[i]}" for i in range(display_count))
        
        if len(strings) > display_count:
            result_list += f"\n... è¿˜æœ‰ {len(strings) - display_count} é¡¹"
        
        return f"{stats}\n\nç»“æœåˆ—è¡¨ï¼š\n{result_list}"
    
    def _format_dict_list(self, dicts: list, counts: dict, total: int, successful: int, failed: int) -> str:
        """æ ¼å¼åŒ–å­—å…¸åˆ—è¡¨ï¼ˆæœç´¢ç»“æœã€ç»“æ„åŒ–æ•°æ®ç­‰ï¼‰"""
        # å°è¯•ä»ç¬¬ä¸€ä¸ªç»“æœä¸­æå–å…³é”®ä¿¡æ¯
        first_result = dicts[0] if dicts else None
        if first_result and isinstance(first_result, dict):
            title = first_result.get('title', '')
            snippet = first_result.get('snippet', first_result.get('description', ''))
            
            # æ¸…ç†æ–‡æœ¬
            title = self._clean_text(title)
            snippet = self._clean_text(snippet)
            
            # å°è¯•æå–ç»“æ„åŒ–ä¿¡æ¯
            extracted_info = self._extract_structured_info_from_text(title + ' ' + snippet, "")
            
            if extracted_info:
                return extracted_info
        
        # å¦‚æœæ— æ³•æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¿”å›æ ¼å¼åŒ–çš„æœç´¢ç»“æœæ‘˜è¦
        # æ„é€ contextå­—å…¸
        context = {'counts': counts}
        return self._format_primary_data(dicts, context)
    
    def _extract_structured_info_from_text(self, text: str, query: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
        # ç®€åŒ–ï¼šç›´æ¥è¿”å›ç©ºï¼Œè®©ä¸»è¦çš„LLMæ€»ç»“æ–¹æ³•å¤„ç†æ‰€æœ‰é€»è¾‘
        return ""
    
    def _extract_fallback_result(self, output: dict, direct_result: str = "") -> str:
        """å…œåº•çš„ç»“æœæå–"""
        # å¦‚æœæœ‰ç›´æ¥ç»“æœä½†æ˜¯æ˜¯é€šç”¨æ¶ˆæ¯ï¼Œå°è¯•æä¾›æ›´å¤šä¿¡æ¯
        if direct_result and self._is_generic_message(direct_result):
            # å°è¯•ä»metadataè·å–æ›´å¤šä¿¡æ¯
            if 'metadata' in output and 'tool_name' in output['metadata']:
                tool_name = output['metadata']['tool_name']
                if 'parameters' in output['metadata']:
                    params = output['metadata']['parameters']
                    if 'query' in params:
                        return f"âœ… å·²å®Œæˆ\"{params['query']}\"çš„æŸ¥è¯¢"
                return f"âœ… {tool_name} æ‰§è¡Œå®Œæˆ"
        
        # å¦‚æœæœ‰ç›´æ¥ç»“æœï¼Œè¿”å›å®ƒ
        if direct_result:
            return direct_result
        
        # æœ€åçš„å°è¯•ï¼šå¦‚æœæœ‰metadataï¼Œæ˜¾ç¤ºä¸€ä¸ªç®€å•çš„å®Œæˆæ¶ˆæ¯
        if 'metadata' in output and 'tool_name' in output['metadata']:
            tool_name = output['metadata']['tool_name']
            return f"âœ… {tool_name} æ‰§è¡Œå®Œæˆ"
        
        # å¦‚æœä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œä½†æœ‰ä»»ä½•å†…å®¹ï¼Œç®€åŒ–æ˜¾ç¤º
        if output:
            # è¿‡æ»¤æ‰è¿‡äºå¤æ‚æˆ–å†—é•¿çš„å­—æ®µ
            simple_info = {}
            for key, value in output.items():
                if key in ['status', 'message', 'result'] and isinstance(value, (str, int, float, bool)):
                    if isinstance(value, str) and len(value) < 600:
                        simple_info[key] = value
                    elif not isinstance(value, str):
                        simple_info[key] = value
            
            if simple_info:
                return json.dumps(simple_info, ensure_ascii=False, indent=2)
        
        return "ä»»åŠ¡æ‰§è¡Œå®Œæˆã€‚"
    
    def _format_primary_data(self, primary_data: list, context: dict) -> str:
        """æ ¼å¼åŒ–ä¸»è¦æ•°æ®åˆ—è¡¨ï¼ˆå¦‚æœç´¢ç»“æœï¼‰"""
        if not primary_data:
            return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
        
        formatted_items = []
        max_items = min(3, len(primary_data))  # æœ€å¤šæ˜¾ç¤º3ä¸ªç»“æœ
        
        for i, item in enumerate(primary_data[:max_items], 1):
            if isinstance(item, dict):
                # æå–æ ‡é¢˜å’Œæè¿°
                title = item.get('title', '').strip()
                description = item.get('snippet', item.get('description', item.get('content', ''))).strip()
                
                # æ¸…ç†æ–‡æœ¬
                title = self._clean_text(title)
                description = self._clean_text(description)
                
                if title:
                    # é™åˆ¶æè¿°é•¿åº¦
                    if description and len(description) > 600:
                        description = description[:600] + "..."
                    
                    if description:
                        formatted_items.append(f"{i}. {title}\n   {description}")
                    else:
                        formatted_items.append(f"{i}. {title}")
        
        if formatted_items:
            result_text = "ğŸ“‹ ç»“æœæ‘˜è¦ï¼š\n\n" + "\n\n".join(formatted_items)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if 'counts' in context:
                total = context['counts'].get('total', len(primary_data))
                result_text += f"\n\nğŸ“Š å…±æ‰¾åˆ° {total} ä¸ªç»“æœ"
            
            return result_text
        
        return "æ‰¾åˆ°ç»“æœï¼Œä½†å†…å®¹ä¸ºç©ºã€‚"
    
    def _format_data_field(self, data, field_name: str) -> str:
        """æ ¼å¼åŒ–æ•°æ®å­—æ®µ"""
        if isinstance(data, list):
            if not data:
                return f"æœªæ‰¾åˆ°{field_name}æ•°æ®ã€‚"
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç›´æ¥æ‹¼æ¥
            if all(isinstance(item, str) for item in data):
                return "\n".join(f"â€¢ {item}" for item in data[:5])  # æœ€å¤š5ä¸ª
            
            # å¦‚æœæ˜¯å¯¹è±¡åˆ—è¡¨ï¼Œæå–å…³é”®ä¿¡æ¯
            items = []
            for i, item in enumerate(data[:3], 1):
                if isinstance(item, dict):
                    # å°è¯•æ‰¾åˆ°æè¿°æ€§å­—æ®µ
                    for key in ['name', 'title', 'description', 'content', 'text']:
                        if key in item and isinstance(item[key], str):
                            items.append(f"{i}. {item[key]}")
                            break
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æè¿°æ€§å­—æ®µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²å€¼
                        for value in item.values():
                            if isinstance(value, str) and len(value) < 600:
                                items.append(f"{i}. {value}")
                                break
            
            return "\n".join(items) if items else f"{field_name}æ•°æ®å¤„ç†å®Œæˆã€‚"
        
        elif isinstance(data, dict):
            # å¯¹äºå­—å…¸ï¼Œæå–å…³é”®çš„é”®å€¼å¯¹
            important_pairs = []
            for key, value in data.items():
                if isinstance(value, (str, int, float)) and str(value).strip():
                    # åªæ˜¾ç¤ºé‡è¦çš„ã€ç®€çŸ­çš„ä¿¡æ¯
                    if len(str(value)) < 600:
                        important_pairs.append(f"{key}: {value}")
            
            if important_pairs:
                return "\n".join(important_pairs[:5])  # æœ€å¤š5ä¸ªé”®å€¼å¯¹
        
        return f"{field_name}æ•°æ®å·²è·å–ã€‚"
    
    def _extract_list_result(self, output: dict) -> str:
        """å¤„ç†åˆ—è¡¨ç±»å‹çš„ç»“æœ"""
        # æ£€æŸ¥é¡¶å±‚æ˜¯å¦ç›´æ¥æ˜¯åˆ—è¡¨ç»“æ„
        if 'result' in output and isinstance(output['result'], list):
            result_list = output['result']
            return self._format_data_field(result_list, "ç»“æœ")
        
        return ""
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not text:
            return ""
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ§åˆ¶å­—ç¬¦
        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        
        # ç§»é™¤ä¸€äº›å¸¸è§çš„æ— ç”¨å­—ç¬¦ï¼Œä½†ä¿ç•™æ›´å¤šæœ‰æ„ä¹‰çš„å­—ç¬¦
        text = re.sub(r'[^\w\s\u4e00-\u9fff,.!?;:()ã€ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰\-_]', '', text)
        
        return text.strip() 

    def _is_response_truncated(self, response: str) -> bool:
        """æ£€æµ‹å›ç­”æ˜¯å¦è¢«æˆªæ–­"""
        if not response:
            return False
        
        response = response.strip()
        
        # æ£€æŸ¥æ˜¯å¦ä»¥ä¸å®Œæ•´çš„å¥å­ç»“å°¾
        truncation_indicators = [
            # ä»¥è¿æ¥è¯ç»“å°¾ï¼ˆè¡¨ç¤ºå¥å­æœªå®Œæˆï¼‰
            r'[ï¼Œ,]\s*$',
            r'(è€Œä¸”|å¹¶ä¸”|ä»¥åŠ|ä¸|å’Œ|æˆ–|ç„¶å|æ¥ç€|åæ¥|å› æ­¤|æ‰€ä»¥|ä½†æ˜¯|ä¸è¿‡|å¯æ˜¯)\s*$',
            r'(çš„|åœ¨|ä¸º|ä»|å‘|åˆ°|ç”±|è¢«|æŠŠ|å¯¹|å…³äº)\s*$',
            # ä»¥ä¸å®Œæ•´çš„æ•°å­—/å¹´ä»½ç»“å°¾
            r'\d{1,3}$',  # å•ç‹¬çš„ä¸å®Œæ•´æ•°å­—
            r'å‰\d*$',    # "å‰XX"æœªå®Œæˆ
            r'å…¬å…ƒ$',     # "å…¬å…ƒ"åé¢åº”è¯¥æœ‰å¹´ä»½
            # ä»¥åŠ¨è¯åŸå½¢ç»“å°¾ï¼ˆé€šå¸¸åé¢è¿˜æœ‰å®¾è¯­ï¼‰
            r'(æ˜¯|åœ¨|æœ‰|æˆä¸º|æ‹…ä»»|å‚ä¸|æ”¯æŒ|åå¯¹|å»ºç«‹|åˆ›ç«‹|å‘ç”Ÿ|æ‹…å½“)\s*$',
            # å…¶ä»–å¸¸è§çš„æˆªæ–­æ¨¡å¼
            r'[ã€‚ï¼ï¼Ÿ][^ã€‚ï¼ï¼Ÿ]*[ï¼Œ,]\s*$',  # å¥å·ååˆæœ‰é€—å·ç»“å°¾
        ]
        
        for pattern in truncation_indicators:
            if re.search(pattern, response):
                return True
        
        # æ£€æŸ¥æœ€åä¸€å¥è¯æ˜¯å¦è¿‡çŸ­ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', response)
        if sentences:
            last_sentence = sentences[-1].strip()
            # å¦‚æœæœ€åä¸€å¥è¯å¾ˆçŸ­ä¸”ä¸æ˜¯å®Œæ•´çš„è¡¨è¾¾ï¼Œå¯èƒ½è¢«æˆªæ–­
            if 1 < len(last_sentence) < 10 and not re.match(r'^(æ˜¯çš„|å¯¹çš„|ä¸æ˜¯|ç¡®å®|å½“ç„¶)$', last_sentence):
                return True
        
        return False 

    def _format_output_with_links(self, text: str) -> str:
        """
        é€šç”¨çš„è¾“å‡ºé“¾æ¥æ ¼å¼åŒ–æ–¹æ³•
        å°†æ–‡æœ¬ä¸­çš„å„ç§é“¾æ¥è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
        """
        if not text or not isinstance(text, str):
            return text
        
        import re
        
        # 1. å¤„ç†å·²ç»å­˜åœ¨çš„Markdowné“¾æ¥ï¼ˆä¿æŒä¸å˜ï¼‰
        markdown_link_pattern = r'\[([^\]]+)\]\([^\)]+\)'
        existing_links = re.findall(markdown_link_pattern, text)
        
        # 2. å¤„ç†è£¸éœ²çš„HTTP/HTTPSé“¾æ¥ï¼ˆä¸åœ¨Markdownæ ¼å¼ä¸­çš„ï¼‰
        # å…ˆä¿æŠ¤å·²æœ‰çš„Markdowné“¾æ¥
        protected_text = text
        placeholders = {}
        
        # ä¿æŠ¤ç°æœ‰çš„Markdowné“¾æ¥
        for i, match in enumerate(re.finditer(markdown_link_pattern, text)):
            placeholder = f"__PROTECTED_LINK_{i}__"
            placeholders[placeholder] = match.group(0)
            protected_text = protected_text.replace(match.group(0), placeholder, 1)
        
        # åŒ¹é…è£¸éœ²çš„é“¾æ¥
        url_pattern = r'(?<![\[\(])(https?://[^\s\)]+)(?![\]\)])'
        
        def replace_bare_url(match):
            url = match.group(1)
            # æ™ºèƒ½æå–é“¾æ¥çš„å‹å¥½åç§°
            friendly_name = self._extract_friendly_link_name(url)
            return f"[{friendly_name}]({url})"
        
        # æ›¿æ¢è£¸éœ²çš„é“¾æ¥
        protected_text = re.sub(url_pattern, replace_bare_url, protected_text)
        
        # æ¢å¤ä¿æŠ¤çš„é“¾æ¥
        for placeholder, original_link in placeholders.items():
            protected_text = protected_text.replace(placeholder, original_link)
        
        return protected_text
    
    def _extract_friendly_link_name(self, url: str) -> str:
        """ä»URLä¸­æå–å‹å¥½çš„é“¾æ¥åç§°"""
        try:
            parsed = urllib.parse.urlparse(url)
            
            # å¤„ç†MinIOç­‰å¯¹è±¡å­˜å‚¨é“¾æ¥
            if 'minio' in parsed.netloc.lower() or '.s3.' in parsed.netloc.lower():
                # ä»è·¯å¾„ä¸­æå–æ–‡ä»¶å
                path_parts = parsed.path.strip('/').split('/')
                if path_parts and path_parts[-1]:
                    filename = path_parts[-1]
                    # ç§»é™¤æŸ¥è¯¢å‚æ•°ä¸­çš„æ—¶é—´æˆ³ç­‰
                    if '?' in filename:
                        filename = filename.split('?')[0]
                    return filename
                return "ä¸‹è½½æ–‡ä»¶"
            
            # å¤„ç†ä¸€èˆ¬çš„æ–‡ä»¶ä¸‹è½½é“¾æ¥
            path = parsed.path.strip('/')
            if path:
                path_parts = path.split('/')
                filename = path_parts[-1]
                
                # å¦‚æœæ–‡ä»¶ååŒ…å«æ–‡ä»¶æ‰©å±•åï¼Œä½¿ç”¨æ–‡ä»¶å
                if '.' in filename and len(filename.split('.')[-1]) <= 5:
                    return filename
                
                # å¦åˆ™ä½¿ç”¨æœ€åä¸¤ä¸ªè·¯å¾„éƒ¨åˆ†
                if len(path_parts) >= 2:
                    return f"{path_parts[-2]}/{filename}"
                
                return filename
            
            # ä½¿ç”¨åŸŸåä½œä¸ºå‹å¥½åç§°
            domain = parsed.netloc.replace('www.', '')
            return domain or "é“¾æ¥"
            
        except Exception:
            # å¦‚æœURLè§£æå¤±è´¥ï¼Œå°è¯•ä»URLæœ«å°¾æå–å¯èƒ½çš„æ–‡ä»¶å
            url_parts = url.split('/')
            if url_parts:
                last_part = url_parts[-1].split('?')[0]  # ç§»é™¤æŸ¥è¯¢å‚æ•°
                if last_part and '.' in last_part:
                    return last_part
            
            return "é“¾æ¥"