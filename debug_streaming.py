#!/usr/bin/env python3
"""
è°ƒè¯•StreamingMCPEngine
"""
import asyncio
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from api.mcp_standard_api import StreamingMCPEngine
from core.mcp_adapter import MCPAdapter

async def debug_streaming():
    """è°ƒè¯•æµå¼å¼•æ“"""
    print("ğŸ” å¼€å§‹è°ƒè¯•StreamingMCPEngine")
    
    # åˆå§‹åŒ–MCPé€‚é…å™¨
    mcp_adapter = MCPAdapter(tool_registry=None, max_sessions=1000)
    
    # åˆå§‹åŒ–æµå¼å¼•æ“
    llm_config = {
        "type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "model": os.getenv("OPENAI_MODEL", "gpt-4-turbo"),
        "base_url": os.getenv("OPENAI_BASE_URL")
    }
    
    streaming_engine = StreamingMCPEngine(llm_config=llm_config, mcp_adapter=mcp_adapter)
    
    print("âœ… StreamingMCPEngineåˆå§‹åŒ–å®Œæˆ")
    
    # æµ‹è¯•å¯¹è¯
    user_input = "æœç´¢å¼ è‰¯çš„èµ„æ–™"
    session_id = "debug_session"
    
    print(f"ğŸ“¤ å‘é€æµ‹è¯•æŸ¥è¯¢: {user_input}")
    
    message_count = 0
    async for result in streaming_engine.execute_streaming_conversation(user_input, session_id):
        message_count += 1
        print(f"ğŸ“¨ [{message_count}] {result.get('type', 'unknown'):15s} - {result.get('message', '')[:50]}...")
        
        if result.get('type') in ['task_complete', 'error']:
            print(f"âœ… æ”¶åˆ°æœ€ç»ˆçŠ¶æ€: {result.get('type')}")
            break
    
    print(f"ğŸ“Š æ€»å…±æ”¶åˆ° {message_count} æ¡æ¶ˆæ¯")

if __name__ == "__main__":
    asyncio.run(debug_streaming()) 