#!/usr/bin/env python3
"""
æµ‹è¯•åŒ…å«file_writerçš„Pipelineæ‰§è¡Œ
"""

import logging
import asyncio
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_pipeline_with_file_writer():
    """æµ‹è¯•åŒ…å«file_writerçš„Pipeline"""
    logger = logging.getLogger("test_pipeline_with_file_writer")
    
    try:
        from core.smart_pipeline_engine import SmartPipelineEngine
        
        logger.info("=== æµ‹è¯•åŒ…å«file_writerçš„Pipeline ===")
        
        # åˆ›å»ºPipelineå¼•æ“
        engine = SmartPipelineEngine(use_llm=False)
        
        # æµ‹è¯•æœç´¢å¹¶å†™å…¥æ–‡ä»¶çš„Pipeline
        test_query = "è¯·æœç´¢æè‡ªæˆçš„ç”Ÿå¹³ç»å†å¹¶ç”ŸæˆæŠ¥å‘Š"
        
        logger.info(f"æ‰§è¡ŒæŸ¥è¯¢: {test_query}")
        
        result = await engine.execute_from_natural_language(test_query)
        
        logger.info("Pipelineæ‰§è¡Œç»“æœ:")
        logger.info(f"  æˆåŠŸ: {result.get('success')}")
        logger.info(f"  æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
        
        if result.get('success'):
            logger.info("  âœ… Pipelineæ‰§è¡ŒæˆåŠŸ")
            
            # æ˜¾ç¤ºèŠ‚ç‚¹ç»“æœ
            node_results = result.get('node_results', [])
            for node_result in node_results:
                node_id = node_result.get('node_id', 'unknown')
                tool_type = node_result.get('tool_type', 'unknown')
                status = node_result.get('status', 'unknown')
                
                logger.info(f"    èŠ‚ç‚¹: {node_id} ({tool_type}) - {status}")
                
                # æ£€æŸ¥file_writerçš„ç»“æœ
                if tool_type == 'file_writer':
                    output = node_result.get('output', {})
                    if output:
                        file_path = output.get('file_path', 'N/A')
                        file_size = output.get('file_size', 0)
                        message = output.get('message', 'N/A')
                        logger.info(f"      æ–‡ä»¶è·¯å¾„: {file_path}")
                        logger.info(f"      æ–‡ä»¶å¤§å°: {file_size} å­—ç¬¦")
                        logger.info(f"      æ¶ˆæ¯: {message}")
                        
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«åˆ›å»º
                        if os.path.exists(file_path):
                            logger.info(f"      âœ… æ–‡ä»¶ç¡®å®å­˜åœ¨: {file_path}")
                            # è¯»å–æ–‡ä»¶å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read(100)
                                logger.info(f"      æ–‡ä»¶å†…å®¹é¢„è§ˆ: {content}...")
                            except Exception as e:
                                logger.error(f"      è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                        else:
                            logger.warning(f"      âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        else:
            errors = result.get('errors', [])
            logger.error(f"  âŒ Pipelineæ‰§è¡Œå¤±è´¥:")
            for error in errors:
                logger.error(f"    - {error}")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_direct_file_writer_in_pipeline():
    """æµ‹è¯•ç›´æ¥åœ¨Pipelineä¸­ä½¿ç”¨file_writer"""
    logger = logging.getLogger("test_direct_file_writer")
    
    try:
        from core.smart_pipeline_engine import SmartPipelineEngine
        
        logger.info("\n=== æµ‹è¯•ç›´æ¥ä½¿ç”¨file_writerçš„Pipeline ===")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„Pipeline
        pipeline = {
            "pipeline_id": "test_file_writer_pipeline",
            "components": [
                {
                    "id": "search_node",
                    "tool_type": "search_tool",
                    "params": {
                        "query": "æè‡ªæˆç”Ÿå¹³ç»å†",
                        "max_results": 3
                    },
                    "output": {
                        "type": "object",
                        "fields": {
                            "results": "æœç´¢ç»“æœåˆ—è¡¨",
                            "status": "æ‰§è¡ŒçŠ¶æ€",
                            "message": "æ‰§è¡Œæ¶ˆæ¯"
                        }
                    }
                },
                {
                    "id": "report_writer_node",
                    "tool_type": "file_writer",
                    "params": {
                        "file_path": "search_report.txt",
                        "text": "æœç´¢ç»“æœæŠ¥å‘Š\n\nåŸºäºæœç´¢ç»“æœçš„æŠ¥å‘Šå†…å®¹..."
                    },
                    "output": {
                        "type": "object",
                        "fields": {
                            "file_path": "è¾“å‡ºæ–‡ä»¶è·¯å¾„",
                            "status": "æ‰§è¡ŒçŠ¶æ€",
                            "message": "æ‰§è¡Œæ¶ˆæ¯"
                        }
                    }
                }
            ]
        }
        
        # æ‰§è¡ŒPipeline
        engine = SmartPipelineEngine(use_llm=False)
        
        # æ‰‹åŠ¨æ‰§è¡ŒPipeline
        start_time = asyncio.get_event_loop().time()
        
        # æ‰§è¡Œç¬¬ä¸€ä¸ªèŠ‚ç‚¹
        search_result = await engine.execute_from_natural_language("è¯·æœç´¢æè‡ªæˆçš„ç”Ÿå¹³ç»å†")
        
        if search_result.get('success'):
            logger.info("æœç´¢èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ")
            
            # æ‰‹åŠ¨æ‰§è¡Œfile_writer
            from tools.file_writer import file_writer
            
            file_result = file_writer(
                "search_report.txt", 
                "æè‡ªæˆç”Ÿå¹³ç»å†æœç´¢æŠ¥å‘Š\n\nè¿™æ˜¯åŸºäºæœç´¢ç»“æœçš„æŠ¥å‘Šå†…å®¹..."
            )
            
            logger.info(f"æ–‡ä»¶å†™å…¥ç»“æœ: {file_result}")
            
            # æ£€æŸ¥æ–‡ä»¶
            if os.path.exists("search_report.txt"):
                logger.info("âœ… æŠ¥å‘Šæ–‡ä»¶åˆ›å»ºæˆåŠŸ")
                
                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                os.remove("search_report.txt")
                logger.info("æ¸…ç†æµ‹è¯•æ–‡ä»¶: search_report.txt")
            else:
                logger.warning("âš ï¸ æŠ¥å‘Šæ–‡ä»¶æœªåˆ›å»º")
        else:
            logger.error("æœç´¢èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    logger = logging.getLogger("main")
    logger.info("å¼€å§‹æµ‹è¯•åŒ…å«file_writerçš„Pipeline...")
    
    # æµ‹è¯•1: è‡ªç„¶è¯­è¨€Pipeline
    success1 = asyncio.run(test_pipeline_with_file_writer())
    
    # æµ‹è¯•2: ç›´æ¥file_writeræµ‹è¯•
    success2 = asyncio.run(test_direct_file_writer_in_pipeline())
    
    if success1 and success2:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼file_writeråœ¨Pipelineä¸­å·¥ä½œæ­£å¸¸")
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥") 