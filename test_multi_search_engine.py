#!/usr/bin/env python3
"""
æµ‹è¯•å¤šæœç´¢å¼•æ“åŠŸèƒ½
"""

import logging
import asyncio
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_multi_search_engine():
    """æµ‹è¯•å¤šæœç´¢å¼•æ“"""
    logger = logging.getLogger("test_multi_search_engine")
    
    try:
        from tools.multi_search_engine import MultiSearchEngine
        
        logger.info("=== æµ‹è¯•å¤šæœç´¢å¼•æ“ ===")
        
        # åˆ›å»ºå¤šæœç´¢å¼•æ“å®ä¾‹
        search_engine = MultiSearchEngine(timeout=10)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æè‡ªæˆç”Ÿå¹³ç»å†",
            "Pythonç¼–ç¨‹æ•™ç¨‹",
            "äººå·¥æ™ºèƒ½å‘å±•"
        ]
        
        for query in test_queries:
            logger.info(f"\n--- æµ‹è¯•æŸ¥è¯¢: {query} ---")
            start_time = time.time()
            
            # æ‰§è¡Œæœç´¢
            results = await search_engine.search(
                query=query,
                num_results=3,
                preferred_engine="google"
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            logger.info(f"æœç´¢è€—æ—¶: {duration:.2f}ç§’")
            logger.info(f"æ‰¾åˆ°ç»“æœæ•°é‡: {len(results)}")
            
            # æ˜¾ç¤ºæœç´¢ç»“æœ
            for i, result in enumerate(results):
                logger.info(f"ç»“æœ{i+1}:")
                logger.info(f"  æ ‡é¢˜: {result.title}")
                logger.info(f"  é“¾æ¥: {result.url}")
                logger.info(f"  æ¥æº: {result.source}")
                if result.description:
                    logger.info(f"  æ‘˜è¦: {result.description[:100]}...")
            
            logger.info("-" * 50)
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_baidu_search_tool():
    """æµ‹è¯•ç™¾åº¦æœç´¢å·¥å…·"""
    logger = logging.getLogger("test_baidu_search_tool")
    
    try:
        from tools.baidu_search_tool import baidu_search_tool
        
        logger.info("\n=== æµ‹è¯•ç™¾åº¦æœç´¢å·¥å…· ===")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æè‡ªæˆç”Ÿå¹³ç»å†",
            "Pythonç¼–ç¨‹æ•™ç¨‹"
        ]
        
        for query in test_queries:
            logger.info(f"\n--- æµ‹è¯•æŸ¥è¯¢: {query} ---")
            start_time = time.time()
            
            # æ‰§è¡Œæœç´¢
            result = baidu_search_tool(query, max_results=3)
            
            end_time = time.time()
            duration = end_time - start_time
            
            logger.info(f"æœç´¢è€—æ—¶: {duration:.2f}ç§’")
            logger.info(f"çŠ¶æ€: {result.get('status')}")
            logger.info(f"æ¥æº: {result.get('source')}")
            logger.info(f"ç»“æœæ•°é‡: {len(result.get('results', []))}")
            
            # æ˜¾ç¤ºæœç´¢ç»“æœ
            results = result.get('results', [])
            for i, item in enumerate(results):
                logger.info(f"ç»“æœ{i+1}:")
                logger.info(f"  æ ‡é¢˜: {item.get('title', 'N/A')}")
                logger.info(f"  é“¾æ¥: {item.get('link', 'N/A')}")
                if item.get('snippet'):
                    logger.info(f"  æ‘˜è¦: {item.get('snippet', '')[:100]}...")
            
            logger.info("-" * 50)
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_search_tool():
    """æµ‹è¯•æœç´¢å·¥å…·"""
    logger = logging.getLogger("test_search_tool")
    
    try:
        from tools.search_tool import search_tool
        
        logger.info("\n=== æµ‹è¯•æœç´¢å·¥å…· ===")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "æè‡ªæˆç”Ÿå¹³ç»å†"
        
        logger.info(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        start_time = time.time()
        
        # æ‰§è¡Œæœç´¢
        result = search_tool(test_query, max_results=3)
        
        end_time = time.time()
        duration = end_time - start_time
        
        logger.info(f"æœç´¢è€—æ—¶: {duration:.2f}ç§’")
        logger.info(f"çŠ¶æ€: {result.get('status')}")
        logger.info(f"æ¥æº: {result.get('source')}")
        logger.info(f"ç»“æœæ•°é‡: {len(result.get('results', []))}")
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        results = result.get('results', [])
        for i, item in enumerate(results):
            logger.info(f"ç»“æœ{i+1}:")
            logger.info(f"  æ ‡é¢˜: {item.get('title', 'N/A')}")
            logger.info(f"  é“¾æ¥: {item.get('link', 'N/A')}")
            if item.get('snippet'):
                logger.info(f"  æ‘˜è¦: {item.get('snippet', '')[:100]}...")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    logger = logging.getLogger("main")
    logger.info("å¼€å§‹æµ‹è¯•å¤šæœç´¢å¼•æ“åŠŸèƒ½...")
    
    # æµ‹è¯•1: å¤šæœç´¢å¼•æ“
    success1 = asyncio.run(test_multi_search_engine())
    
    # æµ‹è¯•2: ç™¾åº¦æœç´¢å·¥å…·
    success2 = asyncio.run(test_baidu_search_tool())
    
    # æµ‹è¯•3: æœç´¢å·¥å…·
    success3 = asyncio.run(test_search_tool())
    
    if success1 and success2 and success3:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šæœç´¢å¼•æ“åŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… è°·æ­Œæœç´¢ä¼˜å…ˆï¼Œè¶…æ—¶åå›é€€åˆ°ç™¾åº¦æœç´¢")
        logger.info("âœ… æœç´¢å·¥å…·é›†æˆæˆåŠŸå®Œæˆï¼")
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥") 