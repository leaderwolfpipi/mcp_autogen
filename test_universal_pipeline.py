#!/usr/bin/env python3
"""
é€šç”¨Pipelineæµ‹è¯• - å±•ç¤ºç³»ç»Ÿçš„é€šç”¨æ€§è®¾è®¡
"""

import asyncio
import logging
import json
from core.smart_pipeline_engine import SmartPipelineEngine
from core.requirement_parser import RequirementParser

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class UniversalRequirementParser(RequirementParser):
    """é€šç”¨LLMè§£æå™¨ - å±•ç¤ºç³»ç»Ÿçš„é€šç”¨æ€§"""
    
    def parse(self, user_input: str) -> dict:
        """æ¨¡æ‹ŸLLMè§£æç»“æœ - æ”¯æŒå¤šç§å·¥å…·ç±»å‹"""
        self.logger.info(f"===é€šç”¨LLMè§£æå¼€å§‹: {user_input}")
        
        # æ ¹æ®è¾“å…¥ç”Ÿæˆæ¨¡æ‹Ÿçš„LLMå“åº”
        mock_response = self._generate_universal_response(user_input)
        
        # æ›¿æ¢pipeline_id
        import uuid
        mock_response["pipeline_id"] = str(uuid.uuid4())
        self.logger.info(f"===é€šç”¨LLMè§£æç»“æœ: {json.dumps(mock_response, ensure_ascii=False)}")
        
        return mock_response
    
    def _generate_universal_response(self, user_input: str) -> dict:
        """ç”Ÿæˆé€šç”¨çš„LLMå“åº” - æ”¯æŒå¤šç§å·¥å…·ç±»å‹"""
        
        # å›¾åƒå¤„ç†ç±»
        if "å›¾ç‰‡" in user_input and "æ”¾å¤§" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "scale_node",
                        "tool_type": "image_scaler",
                        "params": {
                            "image_path": "input_image.jpg",
                            "scale_factor": 3
                        },
                        "output": {
                            "type": "image_path",
                            "key": "scaled_image",
                            "description": "æ”¾å¤§åçš„å›¾ç‰‡"
                        }
                    }
                ]
            }
        
        elif "å›¾ç‰‡" in user_input and "æ—‹è½¬" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "rotate_node",
                        "tool_type": "image_rotator",
                        "params": {
                            "image_path": "input_image.jpg",
                            "angle": 90
                        },
                        "output": {
                            "type": "image_path",
                            "key": "rotated_image",
                            "description": "æ—‹è½¬åçš„å›¾ç‰‡"
                        }
                    }
                ]
            }
        
        # æ–‡æœ¬å¤„ç†ç±»
        elif "æ–‡å­—" in user_input and "ç¿»è¯‘" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "translate_node",
                        "tool_type": "text_translator",
                        "params": {
                            "text": "ç¤ºä¾‹æ–‡æœ¬",
                            "source_lang": "zh",
                            "target_lang": "en"
                        },
                        "output": {
                            "type": "string",
                            "key": "translated_text",
                            "description": "ç¿»è¯‘åçš„æ–‡æœ¬"
                        }
                    }
                ]
            }
        
        elif "æ–‡å­—" in user_input and "æå–" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "extract_node",
                        "tool_type": "text_extractor",
                        "params": {
                            "image_path": "input_image.jpg",
                            "language": "eng+chi_sim"
                        },
                        "output": {
                            "type": "string",
                            "key": "extracted_text",
                            "description": "æå–çš„æ–‡å­—"
                        }
                    }
                ]
            }
        
        # æ–‡ä»¶å¤„ç†ç±»
        elif "æ–‡ä»¶" in user_input and "ä¸Šä¼ " in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "upload_node",
                        "tool_type": "file_uploader",
                        "params": {
                            "file_path": "input_file.txt",
                            "destination": "cloud_storage"
                        },
                        "output": {
                            "type": "string",
                            "key": "upload_url",
                            "description": "ä¸Šä¼ åçš„URL"
                        }
                    }
                ]
            }
        
        # æ•°æ®åˆ†æç±»
        elif "æ•°æ®" in user_input and "åˆ†æ" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "analyze_node",
                        "tool_type": "data_analyzer",
                        "params": {
                            "data_file": "input_data.csv",
                            "analysis_type": "statistical"
                        },
                        "output": {
                            "type": "json",
                            "key": "analysis_result",
                            "description": "åˆ†æç»“æœ"
                        }
                    }
                ]
            }
        
        # å¤åˆæ“ä½œ - å±•ç¤ºpipelineçš„é€šç”¨æ€§
        elif "å›¾ç‰‡" in user_input and "ç„¶å" in user_input:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": [
                    {
                        "id": "process_node",
                        "tool_type": "image_processor",
                        "params": {
                            "image_path": "input_image.jpg",
                            "operation": "enhance"
                        },
                        "output": {
                            "type": "image_path",
                            "key": "processed_image",
                            "description": "å¤„ç†åçš„å›¾ç‰‡"
                        }
                    },
                    {
                        "id": "upload_node",
                        "tool_type": "file_uploader",
                        "params": {
                            "file_path": "$process_node.output",
                            "destination": "cloud_storage"
                        },
                        "output": {
                            "type": "string",
                            "key": "upload_url",
                            "description": "ä¸Šä¼ åçš„URL"
                        }
                    }
                ]
            }
        
        # é»˜è®¤è¿”å›ç©ºç»„ä»¶
        else:
            return {
                "pipeline_id": "auto_generated_uuid",
                "components": []
            }

class UniversalSmartPipelineEngine(SmartPipelineEngine):
    """é€šç”¨æ™ºèƒ½Pipelineå¼•æ“"""
    
    def __init__(self):
        # è°ƒç”¨çˆ¶ç±»çš„__init__æ–¹æ³•
        super().__init__(use_llm=False)
        # æ›¿æ¢ä¸ºé€šç”¨è§£æå™¨
        self.requirement_parser = UniversalRequirementParser(use_llm=False)

async def test_universal_pipeline():
    """æµ‹è¯•é€šç”¨pipelineç³»ç»Ÿ"""
    print("ğŸŒ é€šç”¨Pipelineç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–é€šç”¨å¼•æ“
    engine = UniversalSmartPipelineEngine()
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„pipeline
    test_cases = [
        {
            "input": "è¯·å°†å›¾ç‰‡æ”¾å¤§3å€",
            "description": "å›¾åƒå¤„ç†",
            "expected_tools": ["image_scaler"]
        },
        {
            "input": "è¯·å°†è¿™æ®µæ–‡å­—ç¿»è¯‘æˆè‹±æ–‡",
            "description": "æ–‡æœ¬å¤„ç†",
            "expected_tools": ["text_translator"]
        },
        {
            "input": "è¯·å°†æ–‡ä»¶ä¸Šä¼ åˆ°äº‘å­˜å‚¨",
            "description": "æ–‡ä»¶å¤„ç†",
            "expected_tools": ["file_uploader"]
        },
        {
            "input": "è¯·åˆ†æè¿™ä¸ªæ•°æ®æ–‡ä»¶",
            "description": "æ•°æ®åˆ†æ",
            "expected_tools": ["data_analyzer"]
        },
        {
            "input": "è¯·å¤„ç†å›¾ç‰‡ç„¶åä¸Šä¼ ",
            "description": "å¤åˆæ“ä½œ",
            "expected_tools": ["image_processor", "file_uploader"]
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {test_case['description']}")
        print(f"è¾“å…¥: {test_case['input']}")
        
        # æ‰§è¡Œpipeline
        result = await engine.execute_from_natural_language(test_case['input'])
        
        print(f"æ‰§è¡Œç»“æœ: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        print(f"æ‰§è¡Œæ—¶é—´: {result['execution_time']:.3f}ç§’")
        
        if result['success']:
            print(f"æœ€ç»ˆè¾“å‡º: {result['final_output']}")
            
            # éªŒè¯å·¥å…·ç±»å‹
            if result['node_results']:
                actual_tools = [node['tool_type'] for node in result['node_results']]
                expected_tools = test_case.get('expected_tools', [])
                
                if actual_tools == expected_tools:
                    print(f"âœ… å·¥å…·ç±»å‹åŒ¹é…: {actual_tools}")
                else:
                    print(f"âŒ å·¥å…·ç±»å‹ä¸åŒ¹é…: æœŸæœ› {expected_tools}, å®é™… {actual_tools}")
                
                # æ˜¾ç¤ºèŠ‚ç‚¹æ‰§è¡Œè¯¦æƒ…
                print(f"èŠ‚ç‚¹æ‰§è¡Œè¯¦æƒ…:")
                for node in result['node_results']:
                    print(f"  - {node['node_id']}: {node['status']}")
                    if 'output' in node:
                        print(f"    è¾“å‡º: {node['output']}")
        else:
            print(f"é”™è¯¯: {result['errors']}")

def test_universal_design_principles():
    """æµ‹è¯•é€šç”¨æ€§è®¾è®¡åŸåˆ™"""
    print(f"\nğŸ¯ é€šç”¨æ€§è®¾è®¡åŸåˆ™éªŒè¯")
    print("=" * 60)
    
    # æµ‹è¯•å ä½ç¬¦æœºåˆ¶
    print("1. å ä½ç¬¦æœºåˆ¶æµ‹è¯•")
    from core.placeholder_resolver import PlaceholderResolver
    
    resolver = PlaceholderResolver()
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„èŠ‚ç‚¹è¾“å‡º
    node_outputs = {
        "image_node": resolver.create_node_output(
            "image_node",
            {"type": "image_path", "key": "processed_image", "description": "å¤„ç†åçš„å›¾ç‰‡"},
            "/path/to/processed.jpg"
        ),
        "text_node": resolver.create_node_output(
            "text_node",
            {"type": "string", "key": "extracted_text", "description": "æå–çš„æ–‡æœ¬"},
            "Hello World"
        ),
        "data_node": resolver.create_node_output(
            "data_node",
            {"type": "json", "key": "analysis_result", "description": "åˆ†æç»“æœ"},
            {"mean": 10.5, "std": 2.1}
        )
    }
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„å ä½ç¬¦è§£æ
    test_placeholders = [
        {
            "params": {"file_path": "$image_node.output", "destination": "cloud"},
            "description": "å›¾åƒæ–‡ä»¶ä¸Šä¼ "
        },
        {
            "params": {"text": "$text_node.output", "target_lang": "en"},
            "description": "æ–‡æœ¬ç¿»è¯‘"
        },
        {
            "params": {"data": "$data_node.output", "visualization": "chart"},
            "description": "æ•°æ®å¯è§†åŒ–"
        }
    ]
    
    for test in test_placeholders:
        resolved = resolver.resolve_placeholders(test["params"], node_outputs)
        print(f"  {test['description']}: {test['params']} -> {resolved}")
    
    # æµ‹è¯•å·¥å…·ç”Ÿæˆçš„é€šç”¨æ€§
    print("\n2. å·¥å…·ç”Ÿæˆé€šç”¨æ€§æµ‹è¯•")
    from core.code_generator import CodeGenerator
    
    generator = CodeGenerator(use_llm=False)
    
    test_tools = [
        {"tool": "image_processor", "params": {"image_path": "input.jpg", "operation": "enhance"}},
        {"tool": "text_analyzer", "params": {"text": "sample text", "analysis_type": "sentiment"}},
        {"tool": "data_visualizer", "params": {"data_file": "data.csv", "chart_type": "bar"}},
        {"tool": "file_compressor", "params": {"file_path": "input.txt", "compression": "zip"}}
    ]
    
    for tool_spec in test_tools:
        try:
            code = generator.generate(tool_spec)
            print(f"  âœ… {tool_spec['tool']}: ä»£ç ç”ŸæˆæˆåŠŸ ({len(code)} å­—ç¬¦)")
        except Exception as e:
            print(f"  âŒ {tool_spec['tool']}: ä»£ç ç”Ÿæˆå¤±è´¥ - {e}")

if __name__ == "__main__":
    asyncio.run(test_universal_pipeline())
    test_universal_design_principles() 