#!/usr/bin/env python3
"""
æµ‹è¯•é—²èŠåŠŸèƒ½
"""

import asyncio
import os
from core.smart_pipeline_engine import SmartPipelineEngine

async def test_chat_only():
    """æµ‹è¯•é—²èŠåŠŸèƒ½"""
    
    # åˆå§‹åŒ–å¼•æ“
    engine = SmartPipelineEngine(
        use_llm=True,
        llm_config={
            "llm_model": "gpt-4o",
            "api_key": os.environ.get("OPENAI_API_KEY"),
            "api_base": os.environ.get("OPENAI_API_BASE", "https://api.openai.com/v1")
        }
    )
    
    # æµ‹è¯•é—²èŠè¾“å…¥
    chat_inputs = [
        "ä½ å¥½",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "ä½ æ˜¯è°ï¼Ÿ",
        "è°¢è°¢ä½ çš„å¸®åŠ©",
        "å†è§"
    ]
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•é—²èŠåŠŸèƒ½...")
    
    for user_input in chat_inputs:
        print(f"\nğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        
        try:
            result = await engine.execute_from_natural_language(user_input)
            
            if result["success"]:
                print(f"âœ… æˆåŠŸ: {result['final_output']}")
            else:
                print(f"âŒ å¤±è´¥: {result['errors']}")
                
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")
    
    print("\nğŸ‰ é—²èŠåŠŸèƒ½æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    asyncio.run(test_chat_only()) 