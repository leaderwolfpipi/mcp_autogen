#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åç«¯SSEæµå¼è¾“å‡ºé€»è¾‘æ·±åº¦æ£€æŸ¥
"""

import asyncio
import json
import logging
import time
import os
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from core.protocol_adapter import ProtocolAdapter
from core.task_engine import TaskEngine
from core.tool_registry import ToolRegistry

logging.basicConfig(level=logging.WARNING)

async def test_backend_streaming_logic():
    """æ·±åº¦æµ‹è¯•åç«¯æµå¼é€»è¾‘"""
    
    print("ğŸ” åç«¯SSEæµå¼è¾“å‡ºé€»è¾‘æ·±åº¦æ£€æŸ¥")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡åŠ è½½
    print("ğŸ“‹ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_API_BASE")
    model = os.getenv("OPENAI_MODEL")
    
    print(f"  OPENAI_API_KEY: {'âœ… å·²è®¾ç½®' if api_key else 'âŒ æœªè®¾ç½®'}")
    print(f"  OPENAI_API_BASE: {base_url or 'æœªè®¾ç½®'}")
    print(f"  OPENAI_MODEL: {model or 'gpt-4-turbo'}")
    
    # 2. æ£€æŸ¥TaskEngineåˆå§‹åŒ–
    print(f"\nğŸ¤– TaskEngineåˆå§‹åŒ–æ£€æŸ¥:")
    tool_registry = ToolRegistry("sqlite:///test.db")
    task_engine = TaskEngine(tool_registry)
    
    print(f"  task_engine.llm: {task_engine.llm}")
    print(f"  LLMç±»å‹: {type(task_engine.llm).__name__ if task_engine.llm else 'None'}")
    
    if task_engine.llm:
        print(f"  æ”¯æŒgenerate: {'âœ…' if hasattr(task_engine.llm, 'generate') else 'âŒ'}")
        print(f"  æ”¯æŒgenerate_streaming: {'âœ…' if hasattr(task_engine.llm, 'generate_streaming') else 'âŒ'}")
        
        # æµ‹è¯•LLMè¿æ¥
        try:
            print("  ğŸ§ª æµ‹è¯•LLMè¿æ¥...")
            response = await task_engine.llm.generate("æµ‹è¯•", max_tokens=10)
            print(f"  LLMè¿æ¥: âœ… æˆåŠŸ (å“åº”: {response[:30]}...)")
        except Exception as e:
            print(f"  LLMè¿æ¥: âŒ å¤±è´¥ ({str(e)[:50]}...)")
    
    # 3. æµ‹è¯•æµå¼è¾“å‡ºè·¯å¾„
    print(f"\nğŸ¯ æµå¼è¾“å‡ºè·¯å¾„æµ‹è¯•:")
    
    # æ¨¡æ‹Ÿ_handle_chat_modeçš„æ¡ä»¶åˆ¤æ–­
    query = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½"
    
    if task_engine.llm and hasattr(task_engine.llm, 'generate_streaming'):
        print("âœ… å°†æ‰§è¡ŒçœŸæ­£çš„LLMæµå¼ç”Ÿæˆ")
        
        # æµ‹è¯•æµå¼ç”Ÿæˆ
        try:
            print("  ğŸ§ª æµ‹è¯•LLMæµå¼ç”Ÿæˆ...")
            messages = [{"role": "user", "content": "ç®€å•ä»‹ç»ä¸€ä¸‹AI"}]
            
            chunk_count = 0
            content_buffer = ""
            
            async for chunk in task_engine.llm.generate_streaming(messages, max_tokens=50):
                chunk_count += 1
                if chunk.get('type') == 'content':
                    content = chunk.get('content', '')
                    content_buffer += content
                    print(f"    Chunk {chunk_count}: '{content}' (ç´¯è®¡: {len(content_buffer)}å­—ç¬¦)")
                if chunk_count >= 5:  # é™åˆ¶æ˜¾ç¤º
                    break
            
            print(f"  æµå¼ç”Ÿæˆ: âœ… æˆåŠŸ ({chunk_count}ä¸ªchunks)")
            
        except Exception as e:
            print(f"  æµå¼ç”Ÿæˆ: âŒ å¤±è´¥ ({str(e)[:50]}...)")
            
    elif task_engine.llm and hasattr(task_engine.llm, 'generate'):
        print("âš ï¸ å°†æ‰§è¡Œæ™®é€šLLMç”Ÿæˆï¼ˆéæµå¼ï¼‰")
    else:
        print("âŒ å°†æ‰§è¡Œè§„åˆ™å›å¤ï¼ˆæ— LLMï¼‰")
    
    # 4. æµ‹è¯•å®Œæ•´çš„SSEæµ
    print(f"\nğŸŒŠ å®Œæ•´SSEæµæµ‹è¯•:")
    
    adapter = ProtocolAdapter()
    request = {
        "mcp_version": "1.0",
        "session_id": f"backend_test_{int(time.time())}",
        "request_id": f"backend_req_{int(time.time())}",
        "user_query": query,
        "context": {}
    }
    
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}")
    print("-" * 40)
    
    events = []
    start_time = time.time()
    streaming_events = 0
    
    try:
        stream = adapter.sse_handler.create_sse_stream(request)
        
        async for event_data in stream:
            current_time = time.time()
            relative_time = current_time - start_time
            
            try:
                if isinstance(event_data, str):
                    event = json.loads(event_data)
                else:
                    event = event_data
                
                event_type = event.get('type', 'unknown')
                events.append({
                    'type': event_type,
                    'relative_time': relative_time,
                    'data': event.get('data', {})
                })
                
                time_str = datetime.now().strftime('%H:%M:%S.%f')[:-3]
                
                if event_type == 'status':
                    message = event.get('data', {}).get('message', 'N/A')
                    status_type = event.get('data', {}).get('type', 'unknown')
                    
                    if status_type == 'chat_streaming':
                        streaming_events += 1
                        partial = event.get('data', {}).get('partial_content', '')
                        accumulated = event.get('data', {}).get('accumulated_content', '')
                        print(f"ğŸŒŠ {time_str} (+{relative_time:.3f}s) æµå¼äº‹ä»¶ #{streaming_events}: '{partial}' (ç´¯è®¡: {len(accumulated)}å­—ç¬¦)")
                    else:
                        print(f"ğŸ“Š {time_str} (+{relative_time:.3f}s) çŠ¶æ€: {message}")
                
                elif event_type == 'result':
                    final_response = event.get('data', {}).get('final_response', 'N/A')
                    print(f"âœ… {time_str} (+{relative_time:.3f}s) æœ€ç»ˆç»“æœ: {final_response[:50]}...")
                
                else:
                    print(f"ğŸ” {time_str} (+{relative_time:.3f}s) {event_type}")
                
                # é™åˆ¶äº‹ä»¶æ•°é‡
                if len(events) >= 20:
                    print("... (é™åˆ¶æ˜¾ç¤ºå‰20ä¸ªäº‹ä»¶)")
                    break
                    
            except json.JSONDecodeError:
                print(f"âš ï¸ JSONè§£æå¤±è´¥")
            except Exception as e:
                print(f"âŒ äº‹ä»¶å¤„ç†é”™è¯¯: {e}")
        
        # 5. åˆ†æç»“æœ
        print(f"\nğŸ“Š æµå¼è¾“å‡ºåˆ†æ:")
        print(f"  æ€»äº‹ä»¶æ•°: {len(events)}")
        print(f"  æµå¼äº‹ä»¶æ•°: {streaming_events}")
        
        if len(events) > 1:
            total_time = events[-1]['relative_time'] - events[0]['relative_time']
            print(f"  æ€»æŒç»­æ—¶é—´: {total_time:.3f}ç§’")
            
            # æ£€æŸ¥æ—¶é—´é—´éš”
            intervals = []
            for i in range(1, len(events)):
                interval = events[i]['relative_time'] - events[i-1]['relative_time']
                intervals.append(interval)
            
            if intervals:
                avg_interval = sum(intervals) / len(intervals)
                max_interval = max(intervals)
                min_interval = min(intervals)
                
                print(f"  äº‹ä»¶é—´éš”:")
                print(f"    æœ€å°: {min_interval:.3f}s")
                print(f"    æœ€å¤§: {max_interval:.3f}s") 
                print(f"    å¹³å‡: {avg_interval:.3f}s")
        
        # 6. æµå¼è´¨é‡åˆ¤æ–­
        print(f"\nğŸ¯ æµå¼è¾“å‡ºè´¨é‡åˆ¤æ–­:")
        
        if streaming_events > 0:
            print(f"âœ… æ£€æµ‹åˆ° {streaming_events} ä¸ªçœŸæ­£çš„æµå¼äº‹ä»¶")
            print("   - å†…å®¹æ˜¯é€æ­¥ç”Ÿæˆçš„")
        else:
            print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°æµå¼äº‹ä»¶")
            print("   - å†…å®¹æ˜¯ä¸€æ¬¡æ€§è¿”å›çš„")
            
        # 7. é—®é¢˜è¯Šæ–­
        print(f"\nğŸ”§ é—®é¢˜è¯Šæ–­:")
        
        if not task_engine.llm:
            print("âŒ LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            print("   - æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½")
            print("   - æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆ")
        elif not hasattr(task_engine.llm, 'generate_streaming'):
            print("âŒ LLMå®¢æˆ·ç«¯ä¸æ”¯æŒæµå¼ç”Ÿæˆ")
            print("   - æ£€æŸ¥LLMå®¢æˆ·ç«¯å®ç°")
        elif streaming_events == 0:
            print("âŒ æµå¼ç”Ÿæˆæœªè¢«è§¦å‘")
            print("   - æ£€æŸ¥_handle_chat_modeé€»è¾‘")
            print("   - æ£€æŸ¥æ¨¡å¼æ£€æµ‹ç»“æœ")
        else:
            print("âœ… æµå¼è¾“å‡ºå·¥ä½œæ­£å¸¸")
    
    except Exception as e:
        print(f"âŒ SSEæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def main():
    print("ğŸ¯ ç›®æ ‡: æ·±åº¦æ£€æŸ¥åç«¯SSEæµå¼è¾“å‡ºé€»è¾‘")
    print("è¯´æ˜: é€æ­¥æ£€æŸ¥æ¯ä¸ªç¯èŠ‚ï¼Œæ‰¾å‡ºæµå¼è¾“å‡ºé—®é¢˜çš„æ ¹æœ¬åŸå› ")
    print()
    
    await test_backend_streaming_logic()
    
    print("\n" + "=" * 60)
    print("ğŸ† æ£€æŸ¥å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main()) 