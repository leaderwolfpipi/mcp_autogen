#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•é—²èŠåŠŸèƒ½
"""

import asyncio
import os
from core.smart_pipeline_engine import SmartPipelineEngine

async def test_chat_simple():
    """ç®€å•æµ‹è¯•é—²èŠåŠŸèƒ½"""
    
    # åˆå§‹åŒ–å¼•æ“
    engine = SmartPipelineEngine(
        use_llm=True,
        llm_config={
            "llm_model": "gpt-4o",
            "api_key": os.environ.get("OPENAI_API_KEY"),
            "api_base": os.environ.get("OPENAI_API_BASE", "https://api.openai.com/v1")
        }
    )
    
    # æµ‹è¯•ä¸€ä¸ªç®€å•çš„é—²èŠè¾“å…¥
    user_input = "ä½ å¥½"
    
    print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
    print("ğŸ”„ æ­£åœ¨å¤„ç†...")
    
    try:
        result = await engine.execute_from_natural_language(user_input)
        
        print(f"âœ… æ‰§è¡ŒæˆåŠŸ: {result['success']}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é—²èŠ
        if result.get("final_output") and not result.get("node_results"):
            print(f"ğŸ’¬ é—²èŠå›ç­”: {result['final_output']}")
        else:
            print(f"ğŸ”§ æ‰§è¡ŒèŠ‚ç‚¹: {len(result.get('node_results', []))} ä¸ª")
            for node in result.get('node_results', []):
                print(f"   - {node['tool_type']}: {node.get('status', 'unknown')}")
        
        # æ˜¾ç¤ºæœ€ç»ˆè¾“å‡º
        if result.get("final_output"):
            print(f"ğŸ“¤ æœ€ç»ˆè¾“å‡º: {result['final_output']}")
        else:
            print("âŒ æ²¡æœ‰æœ€ç»ˆè¾“å‡º")
            
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")

if __name__ == "__main__":
    asyncio.run(test_chat_simple()) 